# ğŸ“¦ gomes - Sistema de Mensagens para Arquitetura Hexagonal

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Bootstrap](#-bootstrap)
- [Componentes Principais](#-componentes-principais)
- [CQRS](#-cqrs)
- [Processamento AssÃ­ncrono](#-async-processing)
  - [PadrÃµes de PublicaÃ§Ã£o](#-padrÃµes-de-publicaÃ§Ã£o)
  - [PadrÃµes de Consumo](#-padrÃµes-de-consumo)
  - [ResiliÃªncia](#-resiliÃªncia)
  - [Kafka](#-kafka)
  - [RabbitMQ](#-rabbitmq)
- [Observabilidade](#-observabilidade)

## ğŸ¯ VisÃ£o Geral

O **gomes** Ã© um plugin robusto e flexÃ­vel para sistemas de mensagens em arquitetura hexagonal, implementando padrÃµes de Enterprise Integration Patterns (EIP) e Command Query Responsibility Segregation (CQRS). Este sistema oferece uma abstraÃ§Ã£o completa para comunicaÃ§Ã£o assÃ­ncrona entre componentes, facilitando a construÃ§Ã£o de aplicaÃ§Ãµes distribuÃ­das e escalÃ¡veis.

### CaracterÃ­sticas Principais

- **Arquitetura Hexagonal**: SeparaÃ§Ã£o clara entre domÃ­nio, aplicaÃ§Ã£o e infraestrutura
- **PadrÃ£o CQRS**: SeparaÃ§Ã£o entre comandos (modificaÃ§Ã£o) e queries (consulta)
- **Event-Driven Architecture**: Processamento assÃ­ncrono baseado em eventos
- **Enterprise Integration Patterns**: ImplementaÃ§Ã£o de padrÃµes consolidados da indÃºstria
- **ResiliÃªncia**: Suporte a retry automÃ¡tico e dead letter channels
- **MÃºltiplos Drivers**: Suporte a diferentes sistemas de mensagens (Kafka, RabbitMQ, etc.)
- **Processamento Paralelo**: Suporte a mÃºltiplos processadores concorrentes

### PadrÃµes e Abordagens Utilizadas

- **Message Channel**: ComunicaÃ§Ã£o entre componentes atravÃ©s de canais
- **Message Router**: Roteamento inteligente de mensagens baseado em conteÃºdo
- **Dead Letter Channel**: Gerenciamento de mensagens que falharam no processamento
- **Message Dispatcher**: DistribuiÃ§Ã£o de mensagens para handlers apropriados
- **Event-Driven Consumer**: Consumo assÃ­ncrono com processamento paralelo
- **Polling Consumer**: Consumo periÃ³dico para processamento em lote

### Estrutura de Pastas do Plugin

```
pkg/core/infrastructure/gomes/
â”œâ”€â”€ bus/                    # ImplementaÃ§Ãµes CQRS
â”‚   â”œâ”€â”€ command_bus.go      # Processamento de comandos
â”‚   â”œâ”€â”€ query_bus.go        # Processamento de queries
â”‚   â””â”€â”€ event_bus.go        # Processamento de eventos
â”œâ”€â”€ channel/                # ImplementaÃ§Ãµes de canais
â”‚   â”œâ”€â”€ kafka/              # Driver Kafka
â”‚   â”‚   â”œâ”€â”€ connection.go   # Gerenciamento de conexÃµes
â”‚   â”‚   â”œâ”€â”€ inbound_channel_adapter.go  # Consumo de mensagens
â”‚   â”‚   â”œâ”€â”€ outbound_channel_adapter.go # PublicaÃ§Ã£o de mensagens
â”‚   â”‚   â””â”€â”€ message_translator.go       # TraduÃ§Ã£o de mensagens
â”‚   â”œâ”€â”€ rabbitmq/           # Driver RabbitMQ
â”‚   â”‚   â”œâ”€â”€ connection.go   # Gerenciamento de conexÃµes
â”‚   â”‚   â”œâ”€â”€ inbound_channel_adapter.go  # Consumo de mensagens
â”‚   â”‚   â”œâ”€â”€ outbound_channel_adapter.go # PublicaÃ§Ã£o de mensagens
â”‚   â”‚   â””â”€â”€ message_translator.go       # TraduÃ§Ã£o de mensagens
â”‚   â”œâ”€â”€ pubsub_channel.go   # Canal publish-subscribe
â”‚   â””â”€â”€ point_to_point.go   # Canal point-to-point
â”œâ”€â”€ container/              # Gerenciamento de dependÃªncias
â”‚   â””â”€â”€ generic_container.go
â”œâ”€â”€ message/                # Core do sistema
â”‚   â”œâ”€â”€ message.go          # Estrutura base de mensagens
â”‚   â”œâ”€â”€ message_builder.go  # Builder para construÃ§Ã£o de mensagens
â”‚   â”œâ”€â”€ channel/            # Canais de mensagens
â”‚   â”‚   â””â”€â”€ adapter/        # Adaptadores de canal
â”‚   â”œâ”€â”€ endpoint/           # Endpoints de processamento
â”‚   â”‚   â”œâ”€â”€ event_driven_consumer.go  # Consumer event-driven
â”‚   â”‚   â”œâ”€â”€ polling_consumer.go       # Consumer polling
â”‚   â”‚   â”œâ”€â”€ gateway.go                # Gateway de processamento
â”‚   â”‚   â”œâ”€â”€ message_dispatcher.go     # Dispatcher de mensagens
â”‚   â”‚   â””â”€â”€ interfaces.go             # Interfaces dos endpoints
â”‚   â”œâ”€â”€ handler/            # Handlers de mensagens
â”‚   â”‚   â”œâ”€â”€ dead_letter.go           # Handler para dead letter
â”‚   â”‚   â”œâ”€â”€ retry_handler.go         # Handler para retry
â”‚   â”‚   â”œâ”€â”€ context_handler.go       # Handler de contexto
â”‚   â”‚   â”œâ”€â”€ acknowledge_handler.go   # Handler de acknowledge
â”‚   â”‚   â””â”€â”€ action_handler_activator.go # Ativador de handlers
â”‚   â””â”€â”€ router/             # Roteamento de mensagens
â”‚       â”œâ”€â”€ message_filter.go        # Filtro de mensagens
â”‚       â”œâ”€â”€ recipient_list_router.go # Router de lista de destinatÃ¡rios
â”‚       â””â”€â”€ router_composite.go      # Router composto
â”œâ”€â”€ otel/                   # Observabilidade
â”‚   â”œâ”€â”€ otel.go             # Interface e tipos do OpenTelemetry
â”‚   â””â”€â”€ trace.go            # ImplementaÃ§Ã£o de tracing
â”œâ”€â”€ examples/               # Exemplos de uso
â”‚   â”œâ”€â”€ cqrs/               # Exemplo CQRS
â”‚   â”œâ”€â”€ event_driven_consumer/  # Exemplo de consumer
â”‚   â””â”€â”€ message_publisher/      # Exemplo de publisher
â””â”€â”€ gomes.go                # Entry point principal e API pÃºblica
```

## ğŸš€ Bootstrap

O Bootstrap Ã© o processo de inicializaÃ§Ã£o do gomes, onde todos os componentes sÃ£o registrados e configurados antes do sistema comeÃ§ar a processar mensagens. Este processo Ã© fundamental para garantir que o sistema funcione corretamente.

### Exemplo

```go
package main

import (
    "context"
    "log/slog"
    "os/signal"
    "syscall"
    "time"

    "github.com/jeffersonbrasilino/gomes"
    kafka "github.com/jeffersonbrasilino/gomes/channel/kafka"
)

func main() {
    // Configurar contexto para graceful shutdown
    ctx, stop := signal.NotifyContext(context.Background(), syscall.SIGINT, syscall.SIGTERM)
    defer stop()

    slog.Info("Iniciando gomes...")

    // 1. HABILITAR OBSERVABILIDADE (Opcional)
    // Habilite o tracing do OpenTelemetry se configurado
    gomes.EnableOtelTrace()

    // 2. REGISTRAR HANDLERS
    // Registre todos os handlers de comandos, queries e eventos
    gomes.AddActionHandler(&CreateUserHandler{})
    gomes.AddActionHandler(&GetUserHandler{})
    gomes.AddActionHandler(&UserCreatedEventHandler{})

    // 3. CONFIGURAR CONEXÃ•ES
    // Configure conexÃµes com sistemas de mensagens (Kafka, RabbitMQ, etc.)
    gomes.AddChannelConnection(
        kafka.NewConnection("defaultConKafka", []string{"localhost:9093"}),
    )

    // 4. CONFIGURAR CANAIS DE PUBLICAÃ‡ÃƒO
    // Configure canais para envio de mensagens
    publisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
    )
    gomes.AddPublisherChannel(publisherChannel)

    // Configure canal de Dead Letter Queue
    dlqPublisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.dlq",
    )
    gomes.AddPublisherChannel(dlqPublisherChannel)

    // 5. CONFIGURAR CANAIS DE CONSUMO
    // Configure canais para recebimento de mensagens
    consumerChannel := kafka.NewConsumerChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
        "test_consumer",
    )
    // Configure resiliÃªncia
    consumerChannel.WithRetryTimes(2_000, 3_000)
    consumerChannel.WithDeadLetterChannelName("gomes.dlq")

    gomes.AddConsumerChannel(consumerChannel)

    // 6. INICIAR O SISTEMA
    // Inicie o gomes - este passo Ã© obrigatÃ³rio
    gomes.Start()
    slog.Info("gomes iniciado com sucesso!")

    // 7. CONFIGURAR CONSUMERS
    // Configure e inicie os consumers
    consumer, err := gomes.EventDrivenConsumer("test_consumer")
    if err != nil {
        slog.Error("Erro ao criar consumer", "error", err)
        return
    }

    // Execute consumer com configuraÃ§Ãµes especÃ­ficas
    go consumer.WithAmountOfProcessors(2).
        WithMessageProcessingTimeout(30000).
        WithStopOnError(false).
        Run(ctx)

    // 8. SISTEMA OPERACIONAL
    // Aqui o sistema estÃ¡ pronto para processar mensagens
    slog.Info("Sistema operacional - processando mensagens...")

    // Exemplo de uso dos buses
    go publishMessages(ctx)

    // 9. GRACEFUL SHUTDOWN
    // Aguarde sinal de interrupÃ§Ã£o
    <-ctx.Done()
    slog.Info("Iniciando shutdown gracioso...")

    // Encerre o sistema graciosamente
    gomes.Shutdown()
    slog.Info("gomes encerrado com sucesso!")
}

func publishMessages(ctx context.Context) {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            // Publique comandos
            commandBus := gomes.CommandBusByChannel("gomes.topic")
            commandBus.SendAsync(ctx, &CreateUserCommand{
                Username: "user_" + time.Now().Format("20060102150405"),
                Password: "secure_password",
            })

            // Publique queries
            queryBus := gomes.QueryBusByChannel("gomes.topic")
            queryBus.SendAsync(ctx, &GetUserQuery{
                UserID: "123",
            })

            // Publique eventos
            eventBus := gomes.EventBusByChannel("gomes.topic")
            eventBus.Publish(ctx, &UserCreatedEvent{
                UserID:    "123",
                Username:  "john_doe",
                Timestamp: time.Now(),
            })
        }
    }
}
```

### MÃ©todos de Bootstrap

#### HabilitaÃ§Ã£o de Funcionalidades

- **`EnableOtelTrace()`**: Habilita rastreamento distribuÃ­do com OpenTelemetry
  - Deve ser chamado antes de `Start()` se vocÃª deseja observabilidade
  - Requer configuraÃ§Ã£o prÃ©via do TracerProvider do OpenTelemetry
  - Opcional, mas recomendado para ambientes de produÃ§Ã£o

#### Registro de Componentes

- **`AddActionHandler(handler)`**: Registra handlers de comandos, queries e eventos
  - Suporta qualquer tipo que implemente `ActionHandler[T, U]`
  - Um handler por tipo de aÃ§Ã£o (Command, Query ou Event)
  - Retorna erro se handler jÃ¡ existir para a mesma aÃ§Ã£o

- **`AddChannelConnection(connection)`**: Registra conexÃµes com sistemas de mensagens
  - Suporta Kafka, RabbitMQ e outros drivers
  - Usa singleton pattern - conexÃµes com mesmo nome retornam a mesma instÃ¢ncia
  - Retorna erro se conexÃ£o com mesmo nome jÃ¡ existir

- **`AddPublisherChannel(channel)`**: Registra canais de publicaÃ§Ã£o
  - Usado para enviar mensagens (Commands, Queries, Events)
  - Pode ter mÃºltiplos publishers para canais diferentes
  - Retorna erro se canal com mesmo nome jÃ¡ existir

- **`AddConsumerChannel(channel)`**: Registra canais de consumo
  - Usado para receber e processar mensagens
  - Suporta configuraÃ§Ã£o de retry e dead letter
  - Retorna erro se consumer com mesmo nome jÃ¡ existir

#### Controle do Sistema

- **`Start()`**: Inicia o gomes (obrigatÃ³rio)
  - ConstrÃ³i todos os componentes registrados
  - Estabelece conexÃµes com sistemas de mensagens
  - Registra endpoints padrÃ£o para Command e Query Bus
  - Deve ser chamado apÃ³s registrar todos os componentes

- **`Shutdown()`**: Encerra o sistema graciosamente
  - Para todos os consumers ativos
  - Fecha todos os canais (inbound e outbound)
  - Desconecta de sistemas de mensagens
  - Sempre use em conjunto com defer ou signal handling

- **`ShowActiveEndpoints()`**: Mostra endpoints ativos para debug
  - Lista todos os endpoints registrados
  - Mostra tipo de cada endpoint (Command-Bus, Query-Bus, Event-Bus, Consumer)
  - Ãštil para verificar configuraÃ§Ã£o durante desenvolvimento

#### Acesso aos Buses

- **`CommandBus()`**: Retorna o Command Bus padrÃ£o
  - Usa canal padrÃ£o interno
  - Ideal para uso local sem necessidade de sistema de mensagens

- **`QueryBus()`**: Retorna o Query Bus padrÃ£o
  - Usa canal padrÃ£o interno
  - Ideal para uso local sem necessidade de sistema de mensagens

- **`CommandBusByChannel(channelName)`**: Retorna Command Bus para canal especÃ­fico
  - Cria bus se nÃ£o existir
  - Permite mÃºltiplos buses para diferentes canais
  - Retorna erro se canal existir mas nÃ£o for do tipo Command

- **`QueryBusByChannel(channelName)`**: Retorna Query Bus para canal especÃ­fico
  - Cria bus se nÃ£o existir
  - Permite mÃºltiplos buses para diferentes canais
  - Retorna erro se canal existir mas nÃ£o for do tipo Query

- **`EventBusByChannel(channelName)`**: Retorna Event Bus para canal especÃ­fico
  - Cria bus se nÃ£o existir
  - Permite mÃºltiplos buses para diferentes canais
  - Retorna erro se canal existir mas nÃ£o for do tipo Event

#### CriaÃ§Ã£o de Consumers

- **`EventDrivenConsumer(consumerName)`**: Cria consumer assÃ­ncrono event-driven
  - Processa mensagens em tempo real
  - Suporta processamento paralelo com mÃºltiplos processadores
  - Retorna erro se consumer com mesmo nome jÃ¡ existir
  - Deve ser iniciado com `.Run(ctx)` apÃ³s criaÃ§Ã£o

### Fluxo de InicializaÃ§Ã£o

O gomes segue uma ordem especÃ­fica de inicializaÃ§Ã£o interna:

1. **Registro de Endpoints PadrÃ£o**: Command Bus e Query Bus internos
2. **Build de Action Handlers**: ConstrÃ³i todos os handlers registrados
3. **Build de ConexÃµes**: Estabelece conexÃµes com sistemas de mensagens
4. **Build de Outbound Channels**: Cria canais de publicaÃ§Ã£o
5. **Build de Inbound Channels**: Cria canais de consumo

### Boas PrÃ¡ticas de Bootstrap

1. **Ordem Importante**: Sempre registre handlers antes de iniciar o sistema
2. **Habilite Observabilidade Primeiro**: Chame `EnableOtelTrace()` antes de `Start()`
3. **ConexÃµes Ãšnicas**: Use o mesmo nome de conexÃ£o para reutilizar instÃ¢ncias
4. **Graceful Shutdown**: Sempre configure graceful shutdown para produÃ§Ã£o
5. **Error Handling**: Trate erros durante a inicializaÃ§Ã£o - todos os mÃ©todos `Add*` retornam erro
6. **Logging**: Use logging adequado para monitorar o processo
7. **SeparaÃ§Ã£o de Canais**: Use canais diferentes para Commands, Queries e Events se necessÃ¡rio
8. **NomeaÃ§Ã£o Clara**: Use nomes descritivos para canais e consumers

### Exemplo Completo de Tratamento de Erros

```go
package main

import (
    "log"
    "log/slog"

    "github.com/jeffersonbrasilino/gomes"
    kafka "github.com/jeffersonbrasilino/gomes/channel/kafka"
)

func main() {
    // 1. Habilitar observabilidade
    gomes.EnableOtelTrace()

    // 2. Registrar handlers com tratamento de erro
    if err := gomes.AddActionHandler(&CreateUserHandler{}); err != nil {
        log.Fatalf("Failed to register CreateUserHandler: %v", err)
    }

    // 3. Registrar conexÃµes com tratamento de erro
    if err := gomes.AddChannelConnection(
        kafka.NewConnection("defaultConKafka", []string{"localhost:9093"}),
    ); err != nil {
        log.Fatalf("Failed to add channel connection: %v", err)
    }

    // 4. Registrar canais com tratamento de erro
    publisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
    )
    if err := gomes.AddPublisherChannel(publisherChannel); err != nil {
        log.Fatalf("Failed to add publisher channel: %v", err)
    }

    consumerChannel := kafka.NewConsumerChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
        "test_consumer",
    )
    if err := gomes.AddConsumerChannel(consumerChannel); err != nil {
        log.Fatalf("Failed to add consumer channel: %v", err)
    }

    // 5. Iniciar sistema com tratamento de erro
    if err := gomes.Start(); err != nil {
        log.Fatalf("Failed to start gomes: %v", err)
    }

    slog.Info("gomes started successfully")

    // 6. Criar consumer com tratamento de erro
    consumer, err := gomes.EventDrivenConsumer("test_consumer")
    if err != nil {
        log.Fatalf("Failed to create consumer: %v", err)
    }

    // 7. Mostrar endpoints ativos para debug
    gomes.ShowActiveEndpoints()

    // ... resto da aplicaÃ§Ã£o ...
}
```

## ğŸ”§ Componentes Principais

### Diagrama de Fluxo

```mermaid
flowchart TD
    A[Cliente] -->|1. Envia Mensagem| B[gomes]
    B -->|2. Identifica Tipo| C{Tipo de Mensagem}
    C -->|Command| D[CommandBus]
    C -->|Query| E[QueryBus]
    C -->|Event| F[EventBus]

    D -->|3. Roteia| G[MessageRouter]
    E -->|3. Roteia| G
    F -->|3. Roteia| G

    G -->|4. Despacha| H[MessageHandler]
    H -->|5. Processa| I[Domain Logic]
    I -->|6. Resultado| H
    H -->|7. Resposta| G
    G -->|8. Retorno| B
    B -->|9. Entrega| A

    J[Channel Adapter] -->|Consumo| K[Consumer Endpoint]
    K -->|Processamento| L[Gateway]
    L -->|Retry/Dead Letter| M[Resilience Layer]
```

### Diagrama de ExecuÃ§Ã£o

```mermaid
sequenceDiagram
    participant C as Cliente
    participant MS as gomes
    participant CB as CommandBus
    participant R as Router
    participant H as Handler
    participant D as Domain
    participant CA as ChannelAdapter
    participant CE as ConsumerEndpoint

    Note over C,CE: Fluxo de PublicaÃ§Ã£o
    C->>MS: Send(Command)
    MS->>CB: Route(Command)
    CB->>R: Dispatch(Command)
    R->>H: Handle(Command)
    H->>D: Execute Business Logic
    D-->>H: Result
    H-->>R: Return Result
    R-->>CB: Forward Result
    CB-->>MS: Response
    MS-->>C: Return Result

    Note over C,CE: Fluxo de Consumo
    CA->>CE: Receive Message
    CE->>R: Process Message
    R->>H: Handle Message
    H->>D: Execute Logic
    D-->>H: Result
    H-->>R: Return Result
    R-->>CE: Acknowledge
    CE-->>CA: Message Processed
```

## âš¡ CQRS

O gomes implementa o padrÃ£o **Command Query Responsibility Segregation (CQRS)** de forma nativa, separando claramente as operaÃ§Ãµes de modificaÃ§Ã£o (Commands) das operaÃ§Ãµes de consulta (Queries), alÃ©m de incluir o processamento de eventos (Events) para notificaÃ§Ãµes assÃ­ncronas.

### Arquitetura CQRS no gomes

```mermaid
flowchart TD
    A[Cliente] --> B{Tipo de OperaÃ§Ã£o}

    B -->|ModificaÃ§Ã£o| C[Command Bus]
    B -->|Consulta| D[Query Bus]
    B -->|NotificaÃ§Ã£o| E[Event Bus]

    C --> F[Command Handler]
    D --> G[Query Handler]
    E --> H[Event Handler 1]
    E --> I[Event Handler 2]
    E --> J[Event Handler N]

    F --> K[Domain Logic<br/>ModificaÃ§Ã£o de Estado]
    G --> L[Domain Logic<br/>Leitura de Dados]
    H --> M[Side Effects<br/>Email, Log, etc.]
    I --> M
    J --> M

    K --> N[Resposta SÃ­ncrona]
    L --> N
    M --> O[Processamento AssÃ­ncrono]
```

### Diagrama de ExecuÃ§Ã£o CQRS

```mermaid
sequenceDiagram
    participant C as Cliente
    participant CB as CommandBus
    participant QB as QueryBus
    participant EB as EventBus
    participant CH as CommandHandler
    participant QH as QueryHandler
    participant EH1 as EventHandler1
    participant EH2 as EventHandler2
    participant D as Domain

    Note over C,D: Command Flow
    C->>CB: Send(Command)
    CB->>CH: Handle(Command)
    CH->>D: Execute Business Logic
    D-->>CH: Result
    CH-->>CB: Response
    CB-->>C: Return Result

    Note over C,D: Query Flow
    C->>QB: Send(Query)
    QB->>QH: Handle(Query)
    QH->>D: Read Data
    D-->>QH: Data
    QH-->>QB: Response
    QB-->>C: Return Data

    Note over C,D: Event Flow
    C->>EB: Publish(Event)
    EB->>EH1: Handle(Event)
    EB->>EH2: Handle(Event)
    EH1->>D: Side Effect 1
    EH2->>D: Side Effect 2
    EH1-->>EB: Acknowledged
    EH2-->>EB: Acknowledged
    EB-->>C: Published
```

### ImplementaÃ§Ã£o dos Buses

#### Command Bus

O Command Bus Ã© responsÃ¡vel por processar comandos que modificam o estado do sistema. Cada comando tem exatamente um handler e retorna uma resposta sÃ­ncrona.

```go
// DefiniÃ§Ã£o de um Command
type CreateUserCommand struct {
    Username string `json:"username"`
    Email    string `json:"email"`
    Password string `json:"password"`
}

func (c *CreateUserCommand) Name() string {
    return "CreateUser"
}

// Handler do Command
type CreateUserHandler struct {
    userRepository UserRepository
}

func (h *CreateUserHandler) Handle(ctx context.Context, cmd *CreateUserCommand) (*UserCreatedResult, error) {
    // ValidaÃ§Ã£o
    if cmd.Username == "" || cmd.Email == "" {
        return nil, errors.New("username and email are required")
    }

    // CriaÃ§Ã£o do usuÃ¡rio
    user := &User{
        ID:       uuid.New().String(),
        Username: cmd.Username,
        Email:    cmd.Email,
        Password: hashPassword(cmd.Password),
    }

    // PersistÃªncia
    err := h.userRepository.Save(ctx, user)
    if err != nil {
        return nil, fmt.Errorf("failed to save user: %w", err)
    }

    // Retorno do resultado
    return &UserCreatedResult{
        UserID:   user.ID,
        Username: user.Username,
        Email:    user.Email,
    }, nil
}

// Uso do Command Bus
func createUser() {
    commandBus := gomes.CommandBus()

    result, err := commandBus.Send(context.Background(), &CreateUserCommand{
        Username: "john_doe",
        Email:    "john@example.com",
        Password: "secure_password",
    })

    if err != nil {
        log.Printf("Erro ao criar usuÃ¡rio: %v", err)
        return
    }

    log.Printf("UsuÃ¡rio criado: %+v", result)
}
```

#### Query Bus

O Query Bus Ã© responsÃ¡vel por processar consultas que leem dados do sistema. Cada query tem exatamente um handler e retorna dados sÃ­ncronos.

```go
// DefiniÃ§Ã£o de uma Query
type GetUserByIDQuery struct {
    UserID string `json:"user_id"`
}

func (q *GetUserByIDQuery) Name() string {
    return "GetUserByID"
}

// Handler da Query
type GetUserByIDHandler struct {
    userRepository UserRepository
}

func (h *GetUserByIDHandler) Handle(ctx context.Context, query *GetUserByIDQuery) (*User, error) {
    // Busca o usuÃ¡rio
    user, err := h.userRepository.FindByID(ctx, query.UserID)
    if err != nil {
        return nil, fmt.Errorf("failed to find user: %w", err)
    }

    if user == nil {
        return nil, errors.New("user not found")
    }

    // Retorna os dados (sem informaÃ§Ãµes sensÃ­veis)
    return &User{
        ID:       user.ID,
        Username: user.Username,
        Email:    user.Email,
        // Password nÃ£o Ã© retornado por seguranÃ§a
    }, nil
}

// Uso do Query Bus
func getUser() {
    queryBus := gomes.QueryBus()

    user, err := queryBus.SendAsync(context.Background(), &GetUserByIDQuery{
        UserID: "123",
    })

    if err != nil {
        log.Printf("Erro ao buscar usuÃ¡rio: %v", err)
        return
    }

    log.Printf("UsuÃ¡rio encontrado: %+v", user)
}
```

#### Event Bus

O Event Bus Ã© responsÃ¡vel por processar eventos que notificam sobre mudanÃ§as no sistema. Um evento pode ter mÃºltiplos handlers e Ã© processado de forma assÃ­ncrona.

```go
// DefiniÃ§Ã£o de um Event
type UserCreatedEvent struct {
    UserID    string    `json:"user_id"`
    Username  string    `json:"username"`
    Email     string    `json:"email"`
    Timestamp time.Time `json:"timestamp"`
}

func (e *UserCreatedEvent) Name() string {
    return "UserCreated"
}

// Handler 1: Envio de Email
type UserCreatedEmailHandler struct {
    emailService EmailService
}

func (h *UserCreatedEmailHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Enviar email de boas-vindas
    email := &Email{
        To:      evt.Email,
        Subject: "Bem-vindo!",
        Body:    fmt.Sprintf("OlÃ¡ %s, sua conta foi criada com sucesso!", evt.Username),
    }

    return h.emailService.Send(ctx, email)
}

// Handler 2: Log de Auditoria
type UserCreatedAuditHandler struct {
    auditLogger AuditLogger
}

func (h *UserCreatedAuditHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Registrar no log de auditoria
    return h.auditLogger.Log(ctx, &AuditEntry{
        Action:    "USER_CREATED",
        UserID:    evt.UserID,
        Timestamp: evt.Timestamp,
        Details:   fmt.Sprintf("User %s created with email %s", evt.Username, evt.Email),
    })
}

// Handler 3: NotificaÃ§Ã£o Push
type UserCreatedNotificationHandler struct {
    notificationService NotificationService
}

func (h *UserCreatedNotificationHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Enviar notificaÃ§Ã£o push
    notification := &Notification{
        UserID:  evt.UserID,
        Title:   "Conta Criada",
        Message: "Sua conta foi criada com sucesso!",
        Type:    "SUCCESS",
    }

    return h.notificationService.Send(ctx, notification)
}

// Uso do Event Bus
func publishUserCreated(user *User) {
    eventBus := gomes.EventBus()

    err := eventBus.Publish(context.Background(), &UserCreatedEvent{
        UserID:    user.ID,
        Username:  user.Username,
        Email:     user.Email,
        Timestamp: time.Now(),
    })

    if err != nil {
        log.Printf("Erro ao publicar evento: %v", err)
    }
}
```

### BenefÃ­cios da ImplementaÃ§Ã£o CQRS

1. **SeparaÃ§Ã£o de Responsabilidades**: Commands modificam, Queries leem, Events notificam
2. **Escalabilidade Independente**: Cada tipo pode ser escalado separadamente
3. **OtimizaÃ§Ã£o de Performance**: Queries podem usar views otimizadas
4. **Flexibilidade**: Handlers podem ser adicionados/removidos independentemente
5. **Testabilidade**: Cada handler pode ser testado isoladamente
6. **Manutenibilidade**: CÃ³digo mais organizado e fÃ¡cil de manter

### MÃ©todos dos Buses

#### Command Bus

- **`SendAsync(ctx, command)`**: Envia comando de forma assÃ­ncrona
- **`SendRawAsync(ctx, route, payload, headers)`**: Envia comando com payload e headers customizados

#### Query Bus

- **`SendAsync(ctx, query)`**: Envia query de forma assÃ­ncrona
- **`SendRawAsync(ctx, route, payload, headers)`**: Envia query com payload customizado e headers customizados

#### Event Bus

- **`Publish(ctx, event)`**: Publica evento de forma assÃ­ncrona
- **`PublishRaw(ctx, route, payload, headers)`**: Publica evento com payload customizado e headers customizados

## â± Processamento assÃ­ncrono

### ğŸ“¤ PadrÃµes de PublicaÃ§Ã£o

#### Comandos

Os comandos representam aÃ§Ãµes que modificam o estado do sistema. Eles sÃ£o processados de forma sÃ­ncrona e devem retornar uma resposta.

##### Exemplo de Uso

```go
// 1. Defina seu comando
type CreateUserCommand struct {
    Username string `json:"username"`
    Password string `json:"password"`
}

func (c *CreateUserCommand) Name() string {
    return "createUser"
}

// 2. Implemente o handler
type CreateUserHandler struct{}

func (h *CreateUserHandler) Handle(ctx context.Context, cmd *CreateUserCommand) (*ResultCm, error) {
    // Implemente a lÃ³gica de negÃ³cio
    fmt.Println("process command ok")
    return &ResultCm{"User created successfully"}, nil
}

// 3. Configure e use o sistema
func main() {
    // Configure conexÃ£o Kafka
    gomes.AddChannelConnection(
        kafka.NewConnection("defaultConKafka", []string{"localhost:9093"}),
    )

    // Configure canal de publicaÃ§Ã£o
    publisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
    )
    gomes.AddPublisherChannel(publisherChannel)

    // Registre o handler
    gomes.AddActionHandler(&CreateUserHandler{})

    // Inicie o sistema
    gomes.Start()

    // Use o command bus
    commandBus := gomes.CommandBusByChannel("gomes.topic")
    commandBus.SendAsync(context.Background(), &CreateUserCommand{
        Username: "teste",
        Password: "123",
    })
}
```

##### MÃ©todos do Fluxo de Comando

- **`SendAsync(ctx, command)`**: Envia comando de forma assÃ­ncrona
- **`SendRawAsync(ctx, route, payload, headers)`**: Envia comando com payload customizado
- **`Handle(ctx, command)`**: Processa o comando no handler
- **`Route(command)`**: Roteia o comando para o handler apropriado

#### Queries

As queries representam consultas que nÃ£o modificam o estado do sistema. Elas sÃ£o processadas de forma sÃ­ncrona e retornam dados.

##### Exemplo de Uso

```go
// 1. Defina sua query
type GetUserQuery struct {
    UserID string `json:"user_id"`
}

func (q *GetUserQuery) Name() string {
    return "getUser"
}

// 2. Implemente o handler
type GetUserHandler struct{}

func (h *GetUserHandler) Handle(ctx context.Context, query *GetUserQuery) (*User, error) {
    // Implemente a lÃ³gica de consulta
    return &User{ID: query.UserID, Name: "John Doe"}, nil
}

// 3. Use o query bus
func getUser() {
    queryBus := gomes.QueryBusByChannel("gomes.topic")
    user, err := queryBus.SendAsync(context.Background(), &GetUserQuery{
        UserID: "123",
    })
}
```

##### MÃ©todos do Fluxo de Query

- **`SendAsync(ctx, query)`**: Envia query de forma assÃ­ncrona
- **`SendRawAsync(ctx, route, payload, headers)`**: Envia query com payload customizado
- **`Handle(ctx, query)`**: Processa a query no handler
- **`Route(query)`**: Roteia a query para o handler apropriado

#### Eventos

Os eventos representam notificaÃ§Ãµes sobre mudanÃ§as no sistema. Eles sÃ£o processados de forma assÃ­ncrona e podem ter mÃºltiplos handlers.

##### Exemplo de Uso

```go
// 1. Defina seu evento
type UserCreatedEvent struct {
    UserID    string    `json:"user_id"`
    Username  string    `json:"username"`
    Timestamp time.Time `json:"timestamp"`
}

func (e *UserCreatedEvent) Name() string {
    return "userCreated"
}

// 2. Implemente handlers do evento
type EmailNotificationHandler struct{}

func (h *EmailNotificationHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Enviar email de boas-vindas
    fmt.Printf("Sending welcome email to user %s\n", evt.Username)
    return nil
}

type AuditLogHandler struct{}

func (h *AuditLogHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    // Registrar no log de auditoria
    fmt.Printf("Audit log: User %s created at %s\n", evt.Username, evt.Timestamp)
    return nil
}

// 3. Use o event bus
func publishUserCreated() {
    eventBus := gomes.EventBusByChannel("gomes.topic")
    eventBus.Publish(context.Background(), &UserCreatedEvent{
        UserID:    "123",
        Username:  "john_doe",
        Timestamp: time.Now(),
    })
}
```

##### MÃ©todos do Fluxo de Evento

- **`Publish(ctx, event)`**: Publica evento de forma assÃ­ncrona
- **`PublishRaw(ctx, route, payload, headers)`**: Publica evento com payload customizado
- **`Handle(ctx, event)`**: Processa o evento em todos os handlers registrados
- **`Route(event)`**: Roteia o evento para todos os handlers apropriados

### ğŸ“¥ PadrÃµes de Consumo

#### Event-Driven Consumer

O Event-Driven Consumer processa mensagens de forma assÃ­ncrona e em tempo real, ideal para sistemas que precisam de baixa latÃªncia e alta throughput.

##### CaracterÃ­sticas

- **Processamento AssÃ­ncrono**: Mensagens sÃ£o processadas assim que chegam
- **MÃºltiplos Processadores**: Suporte a processamento paralelo
- **Baixa LatÃªncia**: Processamento imediato das mensagens
- **Alto Throughput**: Capacidade de processar muitas mensagens simultaneamente

##### Exemplo de Uso

```go
func main() {
    // Configure conexÃ£o e canais
    gomes.AddChannelConnection(
        kafka.NewConnection("defaultConKafka", []string{"localhost:9093"}),
    )

    // Configure consumer channel com resiliÃªncia
    topicConsumerChannel := kafka.NewConsumerChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
        "test_consumer",
    )
    topicConsumerChannel.WithRetryTimes(2_000, 3_000)
    topicConsumerChannel.WithDeadLetterChannelName("gomes.dlq")

    // Registre canais e handlers
    gomes.AddConsumerChannel(topicConsumerChannel)
    gomes.AddActionHandler(&CreateUserHandler{})

    // Inicie o sistema
    gomes.Start()

    // Configure event-driven consumer
    consumer, err := gomes.EventDrivenConsumer("test_consumer")
    if err != nil {
        panic(err)
    }

    // Execute com configuraÃ§Ãµes especÃ­ficas
    go consumer.WithAmountOfProcessors(1).
        WithMessageProcessingTimeout(50000).
        WithStopOnError(false).
        Run(ctx)
}
```

##### MÃ©todos do Event-Driven Consumer

- **`WithAmountOfProcessors(count)`**: Define nÃºmero de processadores paralelos
- **`WithMessageProcessingTimeout(timeout)`**: Define timeout para processamento
- **`WithStopOnError(stop)`**: Define se deve parar em caso de erro
- **`Run(ctx)`**: Inicia o processamento assÃ­ncrono

#### Polling Consumer

O Polling Consumer processa mensagens de forma periÃ³dica, ideal para processamento em lote e sistemas que nÃ£o precisam de tempo real.

##### CaracterÃ­sticas

- **Processamento PeriÃ³dico**: Verifica mensagens em intervalos definidos
- **Processamento em Lote**: Ideal para operaÃ§Ãµes que processam mÃºltiplas mensagens
- **Controle de Recursos**: Menor uso de recursos do sistema
- **Maior LatÃªncia**: Processamento nÃ£o Ã© imediato

##### Exemplo de Uso

```go
func main() {
    // Configure consumer polling
    consumer := gomes.NewPollingConsumer("batch-consumer")

    // Configure parÃ¢metros
    consumer.WithPollIntervalMilliseconds(5000)      // Poll a cada 5 segundos
    consumer.WithProcessingDelayMilliseconds(1000)  // Delay de 1 segundo entre processamentos
    consumer.WithProcessingTimeoutMilliseconds(30000) // Timeout de 30 segundos
    consumer.WithStopOnError(false)                  // NÃ£o parar em caso de erro

    // Inicie o polling
    go consumer.Run(ctx)
}
```

##### MÃ©todos do Polling Consumer

- **`WithPollIntervalMilliseconds(interval)`**: Define intervalo de polling
- **`WithProcessingDelayMilliseconds(delay)`**: Define delay entre processamentos
- **`WithProcessingTimeoutMilliseconds(timeout)`**: Define timeout para processamento
- **`WithStopOnError(stop)`**: Define se deve parar em caso de erro
- **`Run(ctx)`**: Inicia o polling periÃ³dico

#### ComparaÃ§Ã£o: Event-Driven vs Polling

| Aspecto             | Event-Driven          | Polling                      |
| ------------------- | --------------------- | ---------------------------- |
| **LatÃªncia**        | Baixa (tempo real)    | Alta (periÃ³dica)             |
| **Throughput**      | Alto                  | MÃ©dio                        |
| **Uso de Recursos** | Alto                  | Baixo                        |
| **Complexidade**    | MÃ©dia                 | Baixa                        |
| **Escalabilidade**  | Excelente             | Boa                          |
| **Casos de Uso**    | Tempo real, streaming | Batch processing, relatÃ³rios |

##### PrÃ³s e Contras

**Event-Driven Consumer:**

âœ… **PrÃ³s:**

- Processamento em tempo real
- Alta eficiÃªncia para streaming
- Escalabilidade horizontal
- Baixa latÃªncia

âŒ **Contras:**

- Maior complexidade de configuraÃ§Ã£o
- Maior uso de recursos
- Pode causar backpressure se nÃ£o configurado adequadamente

**Polling Consumer:**

âœ… **PrÃ³s:**

- Simplicidade de implementaÃ§Ã£o
- Baixo uso de recursos
- Controle preciso sobre quando processar
- Ideal para batch processing

âŒ **Contras:**

- Maior latÃªncia
- Menor throughput
- Pode perder mensagens se o intervalo for muito longo

### ğŸ›¡ï¸ ResiliÃªncia

#### Retry Pattern

O padrÃ£o de retry permite que o sistema tente processar uma mensagem novamente em caso de falha temporÃ¡ria, aumentando a robustez do sistema.

##### Como Funciona

O sistema implementa um handler de retry que envolve o handler original e tenta reprocessar a mensagem em caso de erro, com intervalos configurÃ¡veis entre as tentativas.

##### Diagrama de Fluxo do Retry

```mermaid
flowchart TD
    A[Mensagem Recebida] --> B[Handler Original]
    B --> C{Processamento OK?}
    C -->|Sim| D[Sucesso]
    C -->|NÃ£o| E[Incrementar Tentativa]
    E --> F{Tentativas < MÃ¡ximo?}
    F -->|Sim| G[Aguardar Intervalo]
    G --> H[Tentar Novamente]
    H --> B
    F -->|NÃ£o| I[Falha Final]
    I --> J[Dead Letter Channel]
```

##### Diagrama de ExecuÃ§Ã£o do Retry

```mermaid
sequenceDiagram
    participant M as Message
    participant RH as RetryHandler
    participant OH as OriginalHandler
    participant DLC as DeadLetterChannel

    M->>RH: Process Message
    RH->>OH: Handle Message
    OH-->>RH: Error

    loop Retry Attempts
        RH->>RH: Wait Interval
        RH->>OH: Retry Handle
        OH-->>RH: Error
    end

    RH->>DLC: Send to Dead Letter
    DLC-->>RH: Acknowledged
```

##### Exemplo de ConfiguraÃ§Ã£o

```go
// Configure retry com intervalos especÃ­ficos
topicConsumerChannel := kafka.NewConsumerChannelAdapterBuilder(
    "defaultConKafka",
    "gomes.topic",
    "test_consumer",
)

// Configure retry: [2000ms, 3000ms] - duas tentativas com intervalos de 2s e 3s
topicConsumerChannel.WithRetryTimes(2_000, 3_000)

// Configure dead letter channel
topicConsumerChannel.WithDeadLetterChannelName("gomes.dlq")
```

##### MÃ©todos do Retry Handler

- **`NewRetryHandler(attemptsTime, handler)`**: Cria handler com tentativas configuradas
- **`Handle(ctx, msg)`**: Processa mensagem com retry automÃ¡tico
- **`WithRetryTimes(intervals...)`**: Configura intervalos de retry no consumer

#### Dead Letter Channel

O Dead Letter Channel Ã© um padrÃ£o que captura mensagens que falharam no processamento apÃ³s todas as tentativas de retry, permitindo anÃ¡lise posterior e recuperaÃ§Ã£o manual.

##### Como Funciona

Quando uma mensagem falha apÃ³s todas as tentativas de retry, ela Ã© enviada para um canal especial (Dead Letter Channel) com informaÃ§Ãµes sobre o erro e o payload original.

##### Diagrama de Fluxo do Dead Letter

```mermaid
flowchart TD
    A[Mensagem Processada] --> B{Sucesso?}
    B -->|Sim| C[Processamento ConcluÃ­do]
    B -->|NÃ£o| D[Retry Handler]
    D --> E{Todas Tentativas Falharam?}
    E -->|NÃ£o| F[Tentar Novamente]
    F --> D
    E -->|Sim| G[Dead Letter Handler]
    G --> H[Enriquecer Mensagem]
    H --> I[Enviar para DLQ]
    I --> J[Log do Erro]
    J --> K[Mensagem em DLQ]
```

##### Diagrama de ExecuÃ§Ã£o do Dead Letter

```mermaid
sequenceDiagram
    participant M as Message
    participant DLH as DeadLetterHandler
    participant OH as OriginalHandler
    participant DLC as DeadLetterChannel
    participant DLQ as DeadLetterQueue

    M->>DLH: Process Message
    DLH->>OH: Handle Message
    OH-->>DLH: Error

    DLH->>DLH: Convert Payload
    DLH->>DLH: Create DLQ Message
    DLH->>DLC: Send to DLQ
    DLC->>DLQ: Store Failed Message
    DLQ-->>DLC: Acknowledged
    DLC-->>DLH: Success
    DLH-->>M: Error Returned
```

##### Exemplo de ConfiguraÃ§Ã£o

```go
// 1. Configure canal de dead letter
publisherDlqChannel := kafka.NewPublisherChannelAdapterBuilder(
    "defaultConKafka",
    "gomes.dlq",
)

// 2. Registre o canal de dead letter
gomes.AddPublisherChannel(publisherDlqChannel)

// 3. Configure consumer com dead letter
topicConsumerChannel := kafka.NewConsumerChannelAdapterBuilder(
    "defaultConKafka",
    "gomes.topic",
    "test_consumer",
)
topicConsumerChannel.WithDeadLetterChannelName("gomes.dlq")
```

##### Estrutura da Mensagem Dead Letter

```go
type DeadLetterMessage struct {
    ReasonError string                 `json:"reason_error"`
    Payload     any                    `json:"payload"`
    Headers     map[string]string      `json:"headers"`
}
```

##### MÃ©todos do Dead Letter Handler

- **`NewDeadLetter(channel, handler)`**: Cria handler com dead letter
- **`Handle(ctx, msg)`**: Processa mensagem e envia para DLQ em caso de erro
- **`convertMessagePayload(msg)`**: Converte payload para formato DLQ
- **`makeDeadLetterMessage(ctx, msg, payload)`**: Cria mensagem DLQ enriquecida

### ğŸš€ Kafka

O driver Kafka implementa a integraÃ§Ã£o com Apache Kafka oferecendo adaptadores e tradutores que conectam o modelo de mensagens do `gomes` ao `kafka-go` de forma segura, observÃ¡vel e resiliente.

#### Principais conceitos

- ConexÃµes: gerenciadas por `kafka.NewConnection(name, brokers)` e registradas via `gomes.AddChannelConnection`.
- Publishers: criados com `kafka.NewPublisherChannelAdapterBuilder(connectionName, topic)`.
- Consumers: criados com `kafka.NewConsumerChannelAdapterBuilder(connectionName, topic, groupId)`.
- ResiliÃªncia: suporte a retries e Dead Letter Queue (DLQ) configurÃ¡veis nos builders.

#### ConfiguraÃ§Ã£o de ConexÃ£o

Exemplo mÃ­nimo:

```go
conn := kafka.NewConnection("defaultConKafka", []string{"localhost:9093"})
gomes.AddChannelConnection(conn)
// opcional: conn.Connect() Ã© chamado internamente durante o build do gomes
```

ConfiguraÃ§Ãµes comuns:

- Use mÃºltiplos brokers para alta disponibilidade: `NewConnection("prod", []string{"k1:9092","k2:9092"})`.
- Ã‰ possÃ­vel fornecer TLS via `WithTlsConfig` no builder de conexÃ£o.

#### Publisher (PublicaÃ§Ã£o)

Criar um publisher e registrar:

```go
publisher := kafka.NewPublisherChannelAdapterBuilder("defaultConKafka", "gomes.topic")
// opÃ§Ãµes Ãºteis:
// publisher.WithAsync(true)
// publisher.WithBatchSize(100).WithBatchBytes(1_000_000)
gomes.AddPublisherChannel(publisher)
```

Comportamento:

- O publisher usa `kafka.Writer` do `kafka-go` e converte `message.Message` em `kafka.Message` usando `MessageTranslator.FromMessage`.
- Suporta envio sÃ­ncrono e assÃ­ncrono, batching e controle de acks atravÃ©s de opÃ§Ãµes do builder.

#### Consumer (Consumo)

Criar um consumer com resiliÃªncia:

```go
consumer := kafka.NewConsumerChannelAdapterBuilder("defaultConKafka", "gomes.topic", "test_consumer")
consumer.WithRetryTimes(2000, 3000) // tentativa + backoff simples
consumer.WithDeadLetterChannelName("gomes.dlq")
gomes.AddConsumerChannel(consumer)
```

Comportamento:

- O consumer cria um `kafka.Reader` por `groupId` e lÃª mensagens em loop.
- Cada mensagem Ã© traduzida com `MessageTranslator.ToMessage` e entregue ao `EventDrivenConsumer` do `gomes`.
- Em caso de falha no processamento, aplica-se a polÃ­tica de retry configurada; se esgotadas as tentativas, a mensagem pode ser enviada para a DLQ configurada.

#### TraduÃ§Ã£o de Mensagens

FromMessage (interno â†’ kafka.Message):

- Serializa o payload como JSON no `Value`.
- Mapeia `message.Message` headers para `kafka.Header`.
- Usa `MessageId` como `Key` e `ChannelName` como `Topic`.

ToMessage (kafka.Message â†’ interno):

- Converte `kafka.Header` para headers internos (map[string]string).
- Preserva `Topic`, `Key` (como MessageId) e `Value` (payload JSON â€” decodificar conforme o tipo esperado).
- Propaga cabeÃ§alhos de trace (`traceparent`) quando presentes para integraÃ§Ã£o com OpenTelemetry.

Exemplo rÃ¡pido de uso do tradutor:

```go
mt := kafka.NewMessageTranslator()
internal := mt.ToMessage(kafkaMsg)
kmsg := mt.FromMessage(internal)
```

#### ResiliÃªncia e DLQ

- `WithRetryTimes(initialMs, maxMs)` no consumer config permite retries com backoff simples.
- `WithDeadLetterChannelName(name)` define o canal onde mensagens com falha persistente serÃ£o publicadas.
- RecomendaÃ§Ã£o: use um tÃ³pico DLQ separado por ambiente/serviÃ§o para facilitar triagem.

Fluxo tÃ­pico em erro:

1. Mensagem lida do Kafka.
2. `ToMessage` traduz e envia ao handler do `gomes`.
3. Se o handler falhar, aplica-se retry local (conforme configuraÃ§Ã£o).
4. Se exceder tentativas, constrÃ³i-se uma `DeadLetterMessage` enriquecida e publica-se no tÃ³pico DLQ.

#### Boas prÃ¡ticas

- Configure `GroupID` por serviÃ§o/ambiente para garantir paralelismo seguro.
- Evite usar `MaxBytes` muito alto; prefira mensagens pequenas e compactas.
- Habilite tracing (`gomes.EnableOtelTrace()`) para propagar contexto entre produtores/consumidores.
- Separe tÃ³picos de produÃ§Ã£o e DLQ; monitore DLQ para identificar problemas.

#### ReferÃªncia rÃ¡pida de API

- `kafka.NewConnection(name string, brokers []string)` â†’ cria/retorna conexÃ£o (singleton por nome).
- `(*Connection).Connect() error` â†’ estabelece conexÃµes (opcional manual).
- `kafka.NewPublisherChannelAdapterBuilder(connectionName, topic string)` â†’ builder de publisher.
- `kafka.NewConsumerChannelAdapterBuilder(connectionName, topic, groupId string)` â†’ builder de consumer.
- `(*publisherBuilder).WithAsync(bool)` â†’ habilita envio assÃ­ncrono.
- `(*publisherBuilder).WithBatchSize(int)` / `WithBatchBytes(int)` â†’ controla batching.
- `(*consumerBuilder).WithRetryTimes(initialMs, maxMs int)` â†’ configura retry/backoff.
- `(*consumerBuilder).WithDeadLetterChannelName(name string)` â†’ define DLQ.
- `MessageTranslator.FromMessage(*message.Message) *kafka.Message` â†’ converte para kafka.Message.
- `MessageTranslator.ToMessage(*kafka.Message) *message.Message` â†’ converte para message.Message.

---

O restante da documentaÃ§Ã£o do `Processamento AssÃ­ncrono` segue com a seÃ§Ã£o RabbitMQ.

````

### ğŸ° RabbitMQ

O driver RabbitMQ implementa a integraÃ§Ã£o completa com RabbitMQ (Advanced Message Queuing Protocol), fornecendo adaptadores para publicaÃ§Ã£o e consumo de mensagens com suporte a todas as funcionalidades do gomes. O driver suporta tanto o padrÃ£o de filas (Work Queues) quanto o padrÃ£o de exchanges com routing keys.

#### ConfiguraÃ§Ã£o da ConexÃ£o

##### Exemplo de ConfiguraÃ§Ã£o BÃ¡sica

```go
// Crie uma conexÃ£o RabbitMQ (singleton pattern)
connection := rabbitmq.NewConnection("defaultConRabbitMQ", "localhost:5672")

// Registre a conexÃ£o no sistema
gomes.AddChannelConnection(connection)

// Conecte ao RabbitMQ
err := connection.Connect()
if err != nil {
    log.Fatal("Failed to connect to RabbitMQ:", err)
}
````

##### ConfiguraÃ§Ãµes AvanÃ§adas

```go
// ConfiguraÃ§Ã£o com credenciais e virtual host
connection := rabbitmq.NewConnection(
    "production-rabbitmq",
    "user:password@rabbitmq.example.com:5672/vhost",
)

// Ou apenas com host
connection := rabbitmq.NewConnection(
    "defaultConRabbitMQ",
    "localhost:5672",
)
```

#### Publisher Channel (PublicaÃ§Ã£o)

O driver RabbitMQ suporta dois padrÃµes de publicaÃ§Ã£o:

1. **ProducerQueue**: Publica diretamente para uma fila (Work Queues pattern)
2. **ProducerExchange**: Publica para uma exchange com routing keys (Pub/Sub pattern)

##### ConfiguraÃ§Ã£o do Publisher - Work Queues (PadrÃ£o)

```go
// Crie um publisher channel para fila (padrÃ£o)
publisherChannel := rabbitmq.NewPublisherChannelAdapterBuilder(
    "defaultConRabbitMQ",        // Nome da conexÃ£o
    "gomes.queue",               // Nome da fila de destino
)

// Registre o canal
gomes.AddPublisherChannel(publisherChannel)

// Use o canal atravÃ©s dos buses
commandBus := gomes.CommandBusByChannel("gomes.queue")
queryBus := gomes.QueryBusByChannel("gomes.queue")
eventBus := gomes.EventBusByChannel("gomes.queue")
```

##### ConfiguraÃ§Ã£o do Publisher - Exchange (Pub/Sub)

```go
// Crie um publisher channel para exchange
publisherChannel := rabbitmq.NewPublisherChannelAdapterBuilder(
    "defaultConRabbitMQ",        // Nome da conexÃ£o
    "gomes.exchange",            // Nome da exchange
)

// Configure como exchange
publisherChannel.WithChannelType(rabbitmq.ProducerExchange)

// Configure o tipo de exchange (Direct, Fanout, Topic, Headers)
publisherChannel.WithExchangeType(rabbitmq.ExchangeTopic)

// Configure a routing key para roteamento de mensagens
publisherChannel.WithExchangeRoutingKeys("user.created")

// Registre o canal
gomes.AddPublisherChannel(publisherChannel)

// Use o canal atravÃ©s dos buses
eventBus := gomes.EventBusByChannel("gomes.exchange")
```

##### Tipos de Exchange DisponÃ­veis

O driver RabbitMQ suporta os seguintes tipos de exchange:

- **ExchangeDirect**: Roteamento direto baseado na routing key exata
- **ExchangeFanout**: Distribui mensagens para todas as filas conectadas (broadcast)
- **ExchangeTopic**: Roteamento baseado em padrÃµes de routing key (wildcards)
- **ExchangeHeaders**: Roteamento baseado em headers da mensagem

```go
// Exemplo: Exchange Fanout (broadcast)
publisherChannel := rabbitmq.NewPublisherChannelAdapterBuilder(
    "defaultConRabbitMQ",
    "notifications.exchange",
)
publisherChannel.WithChannelType(rabbitmq.ProducerExchange)
publisherChannel.WithExchangeType(rabbitmq.ExchangeFanout)
// NÃ£o precisa de routing key para Fanout

// Exemplo: Exchange Topic (roteamento por padrÃµes)
publisherChannel := rabbitmq.NewPublisherChannelAdapterBuilder(
    "defaultConRabbitMQ",
    "events.exchange",
)
publisherChannel.WithChannelType(rabbitmq.ProducerExchange)
publisherChannel.WithExchangeType(rabbitmq.ExchangeTopic)
publisherChannel.WithExchangeRoutingKeys("user.*.created") // Wildcard pattern
```

##### TraduÃ§Ã£o de Mensagens

O sistema automaticamente traduz mensagens internas para o formato RabbitMQ:

```go
// Mensagem interna
message := message.NewMessageBuilder().
    WithMessageType(message.Command).
    WithPayload(CreateUserCommand{Username: "john", Password: "123"}).
    WithHeaders(map[string]string{"correlationId": "123"}).
    Build()

// TraduÃ§Ã£o automÃ¡tica para RabbitMQ
rabbitmqMessage := translator.FromMessage(message)
// Resultado: amqp.Publishing com headers, content-type e body JSON
```

#### Consumer Channel (Consumo)

##### ConfiguraÃ§Ã£o do Consumer

```go
// Crie um consumer channel para fila
consumerChannel := rabbitmq.NewConsumerChannelAdapterBuilder(
    "defaultConRabbitMQ",        // Nome da conexÃ£o
    "gomes.queue",               // Nome da fila de origem
    "test_consumer",             // Nome do consumer (opcional)
)

// Configure resiliÃªncia
consumerChannel.WithRetryTimes(2_000, 3_000)  // Retry com intervalos
consumerChannel.WithDeadLetterChannelName("gomes.dlq")  // DLQ

// Registre o canal
gomes.AddConsumerChannel(consumerChannel)
```

##### Consumo de Filas com Exchange

Para consumir mensagens de uma fila que estÃ¡ vinculada a uma exchange:

1. Configure a exchange e as filas no RabbitMQ (via cÃ³digo ou management UI)
2. Configure o consumer apontando para a fila especÃ­fica:

```go
// Consome da fila "user.created.notifications" que estÃ¡ vinculada Ã  exchange
consumerChannel := rabbitmq.NewConsumerChannelAdapterBuilder(
    "defaultConRabbitMQ",
    "user.created.notifications",  // Nome da fila (nÃ£o da exchange)
    "notification_consumer",
)
consumerChannel.WithRetryTimes(2_000, 3_000)
gomes.AddConsumerChannel(consumerChannel)
```

#### Gerenciamento de ConexÃµes

##### Singleton Pattern

O driver RabbitMQ usa singleton pattern para reutilizar conexÃµes:

```go
// Primeira chamada cria a conexÃ£o
conn1 := rabbitmq.NewConnection("defaultConRabbitMQ", "localhost:5672")

// Segunda chamada retorna a mesma instÃ¢ncia
conn2 := rabbitmq.NewConnection("defaultConRabbitMQ", "localhost:5672")

// conn1 == conn2 (mesma instÃ¢ncia)
```

##### MÃ©todos da ConexÃ£o

- **`Connect()`**: Estabelece conexÃ£o com o broker RabbitMQ
- **`Producer(channelName, channelType, exchangeType)`**: Cria producer para fila ou exchange
- **`Consumer(queueName)`**: Cria consumer para fila especÃ­fica
- **`Disconnect()`**: Fecha conexÃ£o e libera recursos
- **`ReferenceName()`**: Retorna nome de referÃªncia da conexÃ£o

#### TraduÃ§Ã£o de Mensagens

##### FromMessage (Interna â†’ RabbitMQ)

```go
func (m *MessageTranslator) FromMessage(msg *message.Message) (*amqp.Publishing, error) {
    // Serializa headers
    headersMap, err := msg.GetHeaders().ToMap()
    if err != nil {
        return nil, err
    }

    // Converte headers para formato RabbitMQ Table
    headers := amqp.Table{}
    for k, v := range headersMap {
        headers[k] = v
    }

    // Serializa payload
    payload, err := json.Marshal(msg.GetPayload())
    if err != nil {
        return nil, err
    }

    return &amqp.Publishing{
        ContentType: "application/json",
        Headers:     headers,
        Body:        payload,
    }, nil
}
```

##### ToMessage (RabbitMQ â†’ Interna)

```go
func (m *MessageTranslator) ToMessage(msg amqp.Delivery) (*message.Message, error) {
    // Converte headers RabbitMQ para headers internos
    headers := map[string]string{}
    for k, h := range msg.Headers {
        if strVal, ok := h.(string); ok {
            headers[k] = strVal
        }
    }

    // Cria mensagem interna a partir dos headers
    messageBuilder, err := message.NewMessageBuilderFromHeaders(headers)
    if err != nil {
        return nil, err
    }

    // Adiciona payload e mensagem raw
    messageBuilder.WithPayload(msg.Body)
    messageBuilder.WithRawMessage(msg)

    return messageBuilder.Build(), nil
}
```

#### Exemplo Completo de Uso - Work Queues

```go
func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // 1. Configure conexÃ£o RabbitMQ
    gomes.AddChannelConnection(
        rabbitmq.NewConnection("defaultConRabbitMQ", "localhost:5672"),
    )

    // 2. Configure publisher para fila
    publisherChannel := rabbitmq.NewPublisherChannelAdapterBuilder(
        "defaultConRabbitMQ",
        "gomes.queue",
    )
    gomes.AddPublisherChannel(publisherChannel)

    // 3. Configure DLQ publisher
    dlqPublisherChannel := rabbitmq.NewPublisherChannelAdapterBuilder(
        "defaultConRabbitMQ",
        "gomes.dlq",
    )
    gomes.AddPublisherChannel(dlqPublisherChannel)

    // 4. Configure consumer com resiliÃªncia
    consumerChannel := rabbitmq.NewConsumerChannelAdapterBuilder(
        "defaultConRabbitMQ",
        "gomes.queue",
        "test_consumer",
    )
    consumerChannel.WithRetryTimes(2_000, 3_000)
    consumerChannel.WithDeadLetterChannelName("gomes.dlq")

    gomes.AddConsumerChannel(consumerChannel)

    // 5. Registre handlers
    gomes.AddActionHandler(&CreateUserHandler{})

    // 6. Inicie o sistema
    gomes.Start()

    // 7. Configure event-driven consumer
    consumer, err := gomes.EventDrivenConsumer("test_consumer")
    if err != nil {
        panic(err)
    }

    // 8. Execute consumer
    go consumer.WithAmountOfProcessors(2).
        WithMessageProcessingTimeout(30000).
        WithStopOnError(false).
        Run(ctx)

    // 9. Publique mensagens
    commandBus := gomes.CommandBusByChannel("gomes.queue")
    commandBus.SendAsync(ctx, &CreateUserCommand{
        Username: "john_doe",
        Password: "secure_password",
    })

    // 10. Graceful shutdown
    <-ctx.Done()
    gomes.Shutdown()
}
```

#### Exemplo Completo de Uso - Exchange (Pub/Sub)

```go
func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // 1. Configure conexÃ£o RabbitMQ
    gomes.AddChannelConnection(
        rabbitmq.NewConnection("defaultConRabbitMQ", "localhost:5672"),
    )

    // 2. Configure publisher para exchange (Topic)
    publisherChannel := rabbitmq.NewPublisherChannelAdapterBuilder(
        "defaultConRabbitMQ",
        "events.exchange",
    )
    publisherChannel.WithChannelType(rabbitmq.ProducerExchange)
    publisherChannel.WithExchangeType(rabbitmq.ExchangeTopic)
    publisherChannel.WithExchangeRoutingKeys("user.created")

    gomes.AddPublisherChannel(publisherChannel)

    // 3. Configure DLQ publisher
    dlqPublisherChannel := rabbitmq.NewPublisherChannelAdapterBuilder(
        "defaultConRabbitMQ",
        "events.dlq",
    )
    gomes.AddPublisherChannel(dlqPublisherChannel)

    // 4. Configure consumer para fila vinculada Ã  exchange
    // Nota: A fila deve estar criada e vinculada Ã  exchange no RabbitMQ
    consumerChannel := rabbitmq.NewConsumerChannelAdapterBuilder(
        "defaultConRabbitMQ",
        "user.created.notifications",  // Nome da fila (nÃ£o da exchange)
        "notification_consumer",
    )
    consumerChannel.WithRetryTimes(2_000, 3_000)
    consumerChannel.WithDeadLetterChannelName("events.dlq")

    gomes.AddConsumerChannel(consumerChannel)

    // 5. Registre handlers
    gomes.AddActionHandler(&UserCreatedNotificationHandler{})

    // 6. Inicie o sistema
    gomes.Start()

    // 7. Configure event-driven consumer
    consumer, err := gomes.EventDrivenConsumer("notification_consumer")
    if err != nil {
        panic(err)
    }

    // 8. Execute consumer
    go consumer.WithAmountOfProcessors(2).
        WithMessageProcessingTimeout(30000).
        WithStopOnError(false).
        Run(ctx)

    // 9. Publique eventos na exchange
    eventBus := gomes.EventBusByChannel("events.exchange")
    eventBus.Publish(ctx, &UserCreatedEvent{
        UserID:    "123",
        Username:  "john_doe",
        Timestamp: time.Now(),
    })

    // 10. Graceful shutdown
    <-ctx.Done()
    gomes.Shutdown()
}
```

#### DiferenÃ§as entre RabbitMQ e Kafka

| Aspecto                    | RabbitMQ                  | Kafka                        |
| -------------------------- | ------------------------- | ---------------------------- |
| **Modelo de ComunicaÃ§Ã£o**  | Filas e Exchanges         | TÃ³picos e PartiÃ§Ãµes          |
| **Routing**                | Routing keys e bindings   | PartiÃ§Ãµes e consumer groups  |
| **Delivery SemÃ¢ntica**     | At-least-once por padrÃ£o  | At-least-once / Exactly-once |
| **Mensagens Persistentes** | Opcional (durable queues) | Sempre persistentes          |
| **PadrÃµes Suportados**     | Work Queues, Pub/Sub      | Pub/Sub, Stream Processing   |
| **ConexÃ£o**                | String Ãºnica (host:port)  | Array de brokers             |
| **Complexidade**           | Menor para casos simples  | Maior, mas mais poderoso     |

#### ConsideraÃ§Ãµes de Performance

- **Connection Pooling**: ReutilizaÃ§Ã£o de conexÃµes para melhor performance
- **Channel Reuse**: Canais RabbitMQ sÃ£o reutilizados quando possÃ­vel
- **Message Acknowledgments**: Gerenciamento automÃ¡tico de ACKs para garantia de entrega
- **Durable Queues/Exchanges**: Suporte a filas e exchanges durÃ¡veis para persistÃªncia
- **Prefetch Count**: ConfiguraÃ§Ã£o automÃ¡tica para controle de throughput

### Monitoramento e Debug

```go
// Visualize conexÃµes ativas
gomes.ShowActiveEndpoints()

// SaÃ­da exemplo:
// ---[Message System] Active Endpoints ---
// Endpoint Name                  | Type
// -------------------------------------------
// gomes.topic            | [outbound] Command-Bus
// gomes.topic            | [outbound] Query-Bus
// gomes.topic            | [outbound] Event-Bus
// gomes.topic            | [inbound] Event-Driven
// gomes.dlq              | [outbound] Dead-Letter
```

## ğŸ” Observabilidade

O **gomes** possui suporte integrado para observabilidade atravÃ©s do **OpenTelemetry**, permitindo rastreamento distribuÃ­do (distributed tracing) de mensagens em sistemas assÃ­ncronos. Isso facilita a identificaÃ§Ã£o de gargalos, anÃ¡lise de performance e debugging de fluxos complexos de mensagens.

### CaracterÃ­sticas Principais

- **Distributed Tracing**: Rastreamento completo de mensagens atravÃ©s de mÃºltiplos serviÃ§os
- **Context Propagation**: PropagaÃ§Ã£o automÃ¡tica de contexto de trace entre mensagens
- **Span Management**: CriaÃ§Ã£o e gerenciamento de spans para operaÃ§Ãµes
- **Events e Attributes**: Registro de eventos e atributos customizados nos spans
- **Status Tracking**: MarcaÃ§Ã£o de sucesso ou erro em operaÃ§Ãµes
- **Integration with Message Systems**: Suporte nativo para Kafka, RabbitMQ e outros sistemas

### Arquitetura de Observabilidade

```mermaid
flowchart TD
    A[Cliente/Produtor] -->|1. Cria Mensagem| B[Command/Query/Event Bus]
    B -->|2. Inicia Span Producer| C[Outbound Channel Adapter]
    C -->|3. Injeta Trace Context| D[Message Headers]
    D -->|4. Publica com TraceID| E[Kafka/RabbitMQ]

    E -->|5. Consome Mensagem| F[Inbound Channel Adapter]
    F -->|6. Extrai Trace Context| G[Consumer Span]
    G -->|7. Propaga Context| H[Message Dispatcher]
    H -->|8. Span de Processamento| I[Handler]
    I -->|9. Finaliza Span| J[Trace Completo]

    C -.->|Link| G

    K[OpenTelemetry Collector] -->|Coleta| C
    K -->|Coleta| G
    K -->|Coleta| H
    K -->|Coleta| I
    K -->|Exporta| L[Jaeger/Zipkin/Datadog]
```

### Diagrama de ExecuÃ§Ã£o do Trace

```mermaid
sequenceDiagram
    participant P as Producer Service
    participant OT as OpenTelemetry
    participant K as Kafka/RabbitMQ
    participant C as Consumer Service
    participant H as Handler
    participant BE as Backend (Jaeger/Zipkin)

    Note over P,BE: Fluxo de Trace DistribuÃ­do

    P->>OT: EnableTrace()
    P->>OT: InitTrace("producer-service")
    P->>OT: Start(ctx, "send CreateUser")
    OT->>P: ctx with TraceID, span

    P->>K: Publish Message + TraceID in Headers
    Note over K: TraceID: abc123<br/>SpanID: xyz789

    K->>C: Consume Message
    C->>OT: Extract TraceID from Headers
    C->>OT: Start(ctx, "process CreateUser")
    OT->>C: ctx with Parent TraceID, new SpanID

    C->>H: Handle(ctx, message)
    H->>OT: AddEvent("user validation")
    H->>OT: AddEvent("user created")
    H->>OT: Success("user created successfully")
    H->>C: Return success

    C->>OT: End span
    P->>OT: End span

    OT->>BE: Export Traces
    BE-->>OT: Acknowledged

    Note over BE: VisualizaÃ§Ã£o do Trace Completo<br/>Producer â†’ Kafka â†’ Consumer â†’ Handler
```

### Habilitando Observabilidade

#### Passo 1: Configurar OpenTelemetry Provider

Primeiro, configure o OpenTelemetry provider com um exporter apropriado (Jaeger, Zipkin, OTLP, etc):

```go
package main

import (
    "context"
    "log"

    "go.opentelemetry.io/otel"
    "go.opentelemetry.io/otel/exporters/jaeger"
    "go.opentelemetry.io/otel/propagation"
    "go.opentelemetry.io/otel/sdk/resource"
    sdktrace "go.opentelemetry.io/otel/sdk/trace"
    semconv "go.opentelemetry.io/otel/semconv/v1.4.0"
)

// InitOtelTraceProvider inicializa o provider do OpenTelemetry
func InitOtelTraceProvider(serviceName string) (*sdktrace.TracerProvider, error) {
    // Configure o exporter (Jaeger neste exemplo)
    exporter, err := jaeger.New(
        jaeger.WithCollectorEndpoint(
            jaeger.WithEndpoint("http://localhost:14268/api/traces"),
        ),
    )
    if err != nil {
        return nil, err
    }

    // Configure o resource com informaÃ§Ãµes do serviÃ§o
    resource := resource.NewWithAttributes(
        semconv.SchemaURL,
        semconv.ServiceNameKey.String(serviceName),
        semconv.ServiceVersionKey.String("1.0.0"),
    )

    // Crie o TracerProvider
    tp := sdktrace.NewTracerProvider(
        sdktrace.WithBatcher(exporter),
        sdktrace.WithResource(resource),
    )

    // Configure o provider global
    otel.SetTracerProvider(tp)

    // Configure o propagator para injetar/extrair contexto de trace
    otel.SetTextMapPropagator(
        propagation.NewCompositeTextMapPropagator(
            propagation.TraceContext{},
            propagation.Baggage{},
        ),
    )

    return tp, nil
}
```

#### Passo 2: Habilitar Tracing no gomes

```go
package main

import (
    "context"
    "log"

    "github.com/jeffersonbrasilino/gomes"
)

func main() {
    // 1. Inicialize o OpenTelemetry Provider
    tp, err := InitOtelTraceProvider("user-service")
    if err != nil {
        log.Fatal("Failed to initialize tracer provider:", err)
    }
    defer tp.Shutdown(context.Background())

    // 2. Habilite tracing no gomes (OBRIGATÃ“RIO)
    gomes.EnableOtelTrace()

    // 3. Configure o gomes normalmente
    // ... configuraÃ§Ã£o de handlers, canais, etc ...

    gomes.Start()

    // O tracing agora estÃ¡ ativo automaticamente
}
```

### Uso AutomÃ¡tico vs Manual

#### Uso AutomÃ¡tico (Recomendado)

O gomes automaticamente cria e gerencia spans para todas as operaÃ§Ãµes de mensagens quando o tracing estÃ¡ habilitado. NÃ£o Ã© necessÃ¡rio nenhum cÃ³digo adicional nos handlers:

```go
// Handler sem cÃ³digo de trace - tracing Ã© automÃ¡tico
type CreateUserHandler struct {
    userRepository UserRepository
}

func (h *CreateUserHandler) Handle(ctx context.Context, cmd *CreateUserCommand) (*UserCreatedResult, error) {
    // O contexto jÃ¡ contÃ©m o span ativo
    // Toda operaÃ§Ã£o serÃ¡ rastreada automaticamente

    user := &User{
        ID:       uuid.New().String(),
        Username: cmd.Username,
        Email:    cmd.Email,
    }

    err := h.userRepository.Save(ctx, user)
    if err != nil {
        return nil, err
    }

    return &UserCreatedResult{
        UserID:   user.ID,
        Username: user.Username,
    }, nil
}
```

**Spans Criados Automaticamente:**

- Span do Producer ao publicar mensagem
- Span do Consumer ao receber mensagem
- Span do Message Dispatcher ao rotear mensagem
- Span do Handler ao processar mensagem

#### Uso Manual (Spans Customizados)

Para criar spans adicionais dentro dos handlers ou adicionar eventos/atributos customizados:

```go
type CreateUserHandler struct {
    userRepository UserRepository
    tracer         otel.OtelTrace
}

func NewCreateUserHandler(repo UserRepository) *CreateUserHandler {
    return &CreateUserHandler{
        userRepository: repo,
        tracer:         otel.InitTrace("user-handler"),
    }
}

func (h *CreateUserHandler) Handle(ctx context.Context, cmd *CreateUserCommand) (*UserCreatedResult, error) {
    // Cria um span customizado para validaÃ§Ã£o
    ctx, validationSpan := h.tracer.Start(
        ctx,
        "validate-user-data",
        otel.WithSpanKind(otel.SpanKindInternal),
        otel.WithAttributes(
            otel.NewOtelAttr("username", cmd.Username),
            otel.NewOtelAttr("email", cmd.Email),
        ),
    )
    defer validationSpan.End()

    // Adiciona evento de validaÃ§Ã£o iniciada
    validationSpan.AddEvent("validation-started")

    // ValidaÃ§Ã£o
    if cmd.Username == "" || cmd.Email == "" {
        validationSpan.Error(
            fmt.Errorf("validation failed"),
            "username and email are required",
        )
        return nil, errors.New("username and email are required")
    }

    // Marca validaÃ§Ã£o como sucesso
    validationSpan.Success("validation completed successfully")
    validationSpan.End()

    // Cria span para operaÃ§Ã£o de banco de dados
    ctx, dbSpan := h.tracer.Start(
        ctx,
        "save-user-to-database",
        otel.WithSpanKind(otel.SpanKindClient),
        otel.WithAttributes(
            otel.NewOtelAttr("db.operation", "insert"),
            otel.NewOtelAttr("db.table", "users"),
        ),
    )
    defer dbSpan.End()

    user := &User{
        ID:       uuid.New().String(),
        Username: cmd.Username,
        Email:    cmd.Email,
    }

    dbSpan.AddEvent("executing-insert")

    err := h.userRepository.Save(ctx, user)
    if err != nil {
        dbSpan.Error(err, "failed to save user to database")
        return nil, fmt.Errorf("failed to save user: %w", err)
    }

    dbSpan.AddEvent("insert-completed")
    dbSpan.Success("user saved successfully")

    return &UserCreatedResult{
        UserID:   user.ID,
        Username: user.Username,
    }, nil
}
```

### Exemplo Completo com CQRS e Tracing

```go
package main

import (
    "context"
    "log"
    "time"

    "github.com/jeffersonbrasilino/gomes"
    "github.com/jeffersonbrasilino/gomes/otel"
    kafka "github.com/jeffersonbrasilino/gomes/channel/kafka"
)

// Command
type CreateUserCommand struct {
    Username string `json:"username"`
    Email    string `json:"email"`
    Password string `json:"password"`
}

func (c *CreateUserCommand) Name() string {
    return "CreateUser"
}

// Query
type GetUserQuery struct {
    UserID string `json:"user_id"`
}

func (q *GetUserQuery) Name() string {
    return "GetUser"
}

// Event
type UserCreatedEvent struct {
    UserID    string    `json:"user_id"`
    Username  string    `json:"username"`
    Email     string    `json:"email"`
    Timestamp time.Time `json:"timestamp"`
}

func (e *UserCreatedEvent) Name() string {
    return "UserCreated"
}

// Handlers
type CreateUserHandler struct {
    tracer otel.OtelTrace
}

func (h *CreateUserHandler) Handle(ctx context.Context, cmd *CreateUserCommand) (*UserCreatedResult, error) {
    // Span customizado para lÃ³gica de negÃ³cio
    ctx, businessSpan := h.tracer.Start(
        ctx,
        "create-user-business-logic",
        otel.WithSpanKind(otel.SpanKindInternal),
    )
    defer businessSpan.End()

    businessSpan.AddEvent("validating-user-data")

    if cmd.Username == "" || cmd.Email == "" {
        businessSpan.Error(
            fmt.Errorf("validation failed"),
            "username and email are required",
        )
        return nil, errors.New("username and email are required")
    }

    businessSpan.AddEvent("creating-user-entity")

    user := &User{
        ID:       uuid.New().String(),
        Username: cmd.Username,
        Email:    cmd.Email,
    }

    businessSpan.AddEvent("user-created",
        otel.NewOtelAttr("user_id", user.ID),
        otel.NewOtelAttr("username", user.Username),
    )

    businessSpan.Success("user created successfully")

    return &UserCreatedResult{
        UserID:   user.ID,
        Username: user.Username,
        Email:    user.Email,
    }, nil
}

type GetUserHandler struct {
    tracer otel.OtelTrace
}

func (h *GetUserHandler) Handle(ctx context.Context, query *GetUserQuery) (*User, error) {
    ctx, querySpan := h.tracer.Start(
        ctx,
        "get-user-query",
        otel.WithSpanKind(otel.SpanKindInternal),
        otel.WithAttributes(
            otel.NewOtelAttr("user_id", query.UserID),
        ),
    )
    defer querySpan.End()

    querySpan.AddEvent("fetching-user-from-database")

    // SimulaÃ§Ã£o de busca no banco
    user := &User{
        ID:       query.UserID,
        Username: "john_doe",
        Email:    "john@example.com",
    }

    querySpan.Success("user retrieved successfully")

    return user, nil
}

type UserCreatedEventHandler struct {
    tracer otel.OtelTrace
}

func (h *UserCreatedEventHandler) Handle(ctx context.Context, evt *UserCreatedEvent) error {
    ctx, eventSpan := h.tracer.Start(
        ctx,
        "process-user-created-event",
        otel.WithSpanKind(otel.SpanKindInternal),
    )
    defer eventSpan.End()

    eventSpan.AddEvent("sending-welcome-email",
        otel.NewOtelAttr("email", evt.Email),
    )

    // LÃ³gica de envio de email
    log.Printf("Sending welcome email to %s", evt.Email)

    eventSpan.Success("welcome email sent successfully")

    return nil
}

func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // 1. Inicialize o OpenTelemetry Provider
    tp, err := InitOtelTraceProvider("user-service")
    if err != nil {
        log.Fatal("Failed to initialize tracer provider:", err)
    }
    defer tp.Shutdown(context.Background())

    // 2. Habilite tracing no gomes
    gomes.EnableOtelTrace()

    // 3. Configure conexÃ£o Kafka
    gomes.AddChannelConnection(
        kafka.NewConnection("defaultConKafka", []string{"localhost:9093"}),
    )

    // 4. Configure canais
    publisherChannel := kafka.NewPublisherChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
    )
    gomes.AddPublisherChannel(publisherChannel)

    consumerChannel := kafka.NewConsumerChannelAdapterBuilder(
        "defaultConKafka",
        "gomes.topic",
        "user_consumer",
    )
    gomes.AddConsumerChannel(consumerChannel)

    // 5. Registre handlers com tracing
    gomes.AddActionHandler(&CreateUserHandler{
        tracer: otel.InitTrace("create-user-handler"),
    })
    gomes.AddActionHandler(&GetUserHandler{
        tracer: otel.InitTrace("get-user-handler"),
    })
    gomes.AddActionHandler(&UserCreatedEventHandler{
        tracer: otel.InitTrace("user-created-event-handler"),
    })

    // 6. Inicie o sistema
    gomes.Start()

    // 7. Configure consumer
    consumer, _ := gomes.EventDrivenConsumer("user_consumer")
    go consumer.WithAmountOfProcessors(2).Run(ctx)

    // 8. Publique mensagens - cada uma serÃ¡ rastreada
    go func() {
        time.Sleep(2 * time.Second)

        commandBus := gomes.CommandBusByChannel("gomes.topic")

        // Este comando gerarÃ¡ um trace completo:
        // Producer Span â†’ Kafka â†’ Consumer Span â†’ Dispatcher Span â†’ Handler Span
        commandBus.SendAsync(ctx, &CreateUserCommand{
            Username: "john_doe",
            Email:    "john@example.com",
            Password: "secure_password",
        })

        queryBus := gomes.QueryBusByChannel("gomes.topic")
        queryBus.SendAsync(ctx, &GetUserQuery{
            UserID: "123",
        })

        eventBus := gomes.EventBusByChannel("gomes.topic")
        eventBus.Publish(ctx, &UserCreatedEvent{
            UserID:    "123",
            Username:  "john_doe",
            Email:     "john@example.com",
            Timestamp: time.Now(),
        })
    }()

    // 9. Aguarde
    <-ctx.Done()
    gomes.Shutdown()
}
```

### ConfiguraÃ§Ãµes de Span

#### Tipos de Span Kind

```go
// SpanKindInternal - operaÃ§Ãµes internas (default)
otel.WithSpanKind(otel.SpanKindInternal)

// SpanKindServer - operaÃ§Ã£o de servidor (recebe requisiÃ§Ã£o)
otel.WithSpanKind(otel.SpanKindServer)

// SpanKindClient - operaÃ§Ã£o de cliente (faz requisiÃ§Ã£o)
otel.WithSpanKind(otel.SpanKindClient)

// SpanKindProducer - produÃ§Ã£o de mensagem
otel.WithSpanKind(otel.SpanKindProducer)

// SpanKindConsumer - consumo de mensagem
otel.WithSpanKind(otel.SpanKindConsumer)
```

#### Tipos de OperaÃ§Ã£o de Mensagem

```go
// OperaÃ§Ã£o de envio de mensagem
otel.WithSpanOperation(otel.SpanOperationSend)

// OperaÃ§Ã£o de recebimento de mensagem
otel.WithSpanOperation(otel.SpanOperationReceive)

// OperaÃ§Ã£o de processamento de mensagem
otel.WithSpanOperation(otel.SpanOperationProcess)

// OperaÃ§Ã£o de criaÃ§Ã£o de mensagem
otel.WithSpanOperation(otel.SpanOperationCreate)

// OperaÃ§Ã£o de confirmaÃ§Ã£o de mensagem
otel.WithSpanOperation(otel.SpanOperationSettle)
```

#### Tipos de Sistema de Mensagens

```go
// Sistemas suportados
otel.WithMessagingSystemType(otel.MessageSystemTypeKafka)
otel.WithMessagingSystemType(otel.MessageSystemTypeRabbitMQ)
otel.WithMessagingSystemType(otel.MessageSystemTypeActiveMQ)
otel.WithMessagingSystemType(otel.MessageSystemTypeSQS)
otel.WithMessagingSystemType(otel.MessageSystemTypeSNS)
otel.WithMessagingSystemType(otel.MessageSystemTypeGCPPubSub)
otel.WithMessagingSystemType(otel.MessageSystemTypePulsar)
otel.WithMessagingSystemType(otel.MessageSystemTypeRocketMQ)
```

### MÃ©todos da Interface OtelTrace

- **`Start(ctx, name, options...)`**: Inicia um novo span
- **`End()`**: Finaliza o span
- **`AddEvent(message, attributes...)`**: Adiciona evento ao span
- **`SetStatus(status, description)`**: Define status do span
- **`Success(message)`**: Marca span como sucesso
- **`Error(err, message)`**: Marca span como erro

### Atributos AutomÃ¡ticos em Mensagens

Quando vocÃª usa `otel.WithMessage(message)`, os seguintes atributos sÃ£o automaticamente adicionados:

- `messaging.message.id`: ID Ãºnico da mensagem
- `messaging.message.correlationId`: ID de correlaÃ§Ã£o
- `command.name`: Nome do comando/query/evento
- `messaging.type`: Tipo de mensagem (Command, Query, Event)
- `command.version`: VersÃ£o da mensagem
- `messaging.destination.name`: Nome do canal de destino
- `messaging.system`: Sistema de mensagens (kafka, rabbitmq, etc)
- `messaging.operation.type`: Tipo de operaÃ§Ã£o (send, receive, process)

### PropagaÃ§Ã£o de Contexto

O gomes automaticamente propaga o contexto de trace atravÃ©s dos headers das mensagens:

```go
// Ao publicar uma mensagem, o TraceID Ã© automaticamente injetado nos headers
commandBus.SendAsync(ctx, command)
// Headers incluem: traceparent, tracestate

// Ao consumir, o TraceID Ã© automaticamente extraÃ­do e o contexto restaurado
// O handler recebe um context com o trace parent configurado
```

### IntegraÃ§Ã£o com Backends

#### Jaeger

```go
import "go.opentelemetry.io/otel/exporters/jaeger"

exporter, err := jaeger.New(
    jaeger.WithCollectorEndpoint(
        jaeger.WithEndpoint("http://localhost:14268/api/traces"),
    ),
)
```

#### Zipkin

```go
import "go.opentelemetry.io/otel/exporters/zipkin"

exporter, err := zipkin.New(
    "http://localhost:9411/api/v2/spans",
)
```

#### OTLP (OpenTelemetry Protocol)

```go
import "go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc"

exporter, err := otlptracegrpc.New(
    context.Background(),
    otlptracegrpc.WithEndpoint("localhost:4317"),
    otlptracegrpc.WithInsecure(),
)
```

### VisualizaÃ§Ã£o de Traces

ApÃ³s configurar um backend como Jaeger, vocÃª pode visualizar:

- **Trace completo**: Da publicaÃ§Ã£o atÃ© o processamento final
- **LatÃªncia**: Tempo gasto em cada etapa
- **Erros**: Onde e quando ocorreram falhas
- **DependÃªncias**: Relacionamento entre serviÃ§os
- **Gargalos**: IdentificaÃ§Ã£o de componentes lentos

**Exemplo de Trace no Jaeger:**

```
user-service: send CreateUser (10ms)
  â””â”€> kafka-outbound-channel-adapter: publish (5ms)
      â””â”€> kafka: message in transit (100ms)
          â””â”€> kafka-inbound-channel-adapter: consume (3ms)
              â””â”€> event-driven-consumer: receive (2ms)
                  â””â”€> message-dispatcher: route (1ms)
                      â””â”€> create-user-handler: process (45ms)
                          â”œâ”€> validate-user-data (5ms)
                          â””â”€> save-user-to-database (40ms)
```

### Boas PrÃ¡ticas

1. **Sempre habilite trace em produÃ§Ã£o**: Use sampling para controlar volume
2. **Adicione atributos relevantes**: Facilita busca e anÃ¡lise
3. **Use eventos para milestones**: Marque pontos importantes do processamento
4. **Marque erros explicitamente**: Use `span.Error()` para registrar falhas
5. **NÃ£o crie spans desnecessÃ¡rios**: Evite overhead em operaÃ§Ãµes triviais
6. **Propague contexto corretamente**: Sempre passe o context atualizado
7. **Configure timeout adequado**: Para evitar traces incompletos
8. **Use span links**: Para relacionar traces em processamento assÃ­ncrono

### Troubleshooting

#### Traces nÃ£o aparecem no backend

1. Verifique se `gomes.EnableOtelTrace()` foi chamado
2. Confirme que o TracerProvider foi inicializado
3. Verifique a conectividade com o backend (Jaeger/Zipkin)
4. Confirme que o exporter estÃ¡ configurado corretamente

#### Contexto nÃ£o Ã© propagado

1. Certifique-se de usar o context retornado por `tracer.Start()`
2. Verifique se o propagator estÃ¡ configurado no otel global
3. Confirme que os headers estÃ£o sendo injetados/extraÃ­dos corretamente

#### Performance degradada

1. Ajuste a taxa de sampling se estiver em 100%
2. Use batch exporter em vez de export sÃ­ncrono
3. Reduza quantidade de atributos e eventos customizados
4. Considere desabilitar trace em operaÃ§Ãµes de alta frequÃªncia

---

> ğŸ’¡ **Nota**: Esta documentaÃ§Ã£o Ã© um guia completo para desenvolvedores que desejam utilizar o gomes em suas aplicaÃ§Ãµes. O sistema foi projetado para ser intuitivo para desenvolvedores jÃºnior, mas poderoso o suficiente para cenÃ¡rios complexos de produÃ§Ã£o.
