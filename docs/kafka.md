# ğŸ¯ Kafka Channel Adapters

**Tipo**: Message Broker Integration  
**Objetivo**: Integrar Apache Kafka como message broker para publicar e consumir mensagens no Gomes  
**Status**: âœ… ProduÃ§Ã£o

---

## ğŸ“– O que Ã©?

Os **Kafka Channel Adapters** do Gomes implementam a integraÃ§Ã£o completa com Apache Kafka, permitindo usar Kafka como message broker para publicar e consumir eventos em aplicaÃ§Ãµes distribuÃ­das. O pacote estÃ¡ dividido em 4 componentes principais:

1. **Connection** - Gerencia conexÃµes com brokers Kafka (producer e consumer)
2. **Outbound Channel Adapter** - Publisher para enviar mensagens para tÃ³picos Kafka
3. **Inbound Channel Adapter** - Consumer para ler mensagens de tÃ³picos Kafka
4. **Message Translator** - Traduz entre o formato interno do Gomes e o formato Kafka

Os adaptadores abstraem a complexidade do cliente Kafka (`segmentio/kafka-go`), permitindo usar o Gomes de forma simples enquanto aproveita a robustez e escalabilidade do Kafka. VocÃª configura conexÃ£o, tÃ³pico e processador - o resto Ã© automÃ¡tico.

### Quando Usar

- âœ… **Alto volume de mensagens**: Kafka Ã© otimizado para throughput massivo
- âœ… **Event Sourcing**: Kafka armazena histÃ³rico completo de eventos
- âœ… **Reprocessamento**: Retroceder no offset para reprocessar eventos
- âœ… **Multi-datacenter**: ReplicaÃ§Ã£o e disaster recovery nativa
- âœ… **MicrosserviÃ§os distribuÃ­dos**: ComunicaÃ§Ã£o assÃ­ncrona entre serviÃ§os
- âœ… **Logs centralizados**: Usar Kafka como hub de eventos de toda arquitetura

### Quando NÃƒO Usar

- âŒ **LatÃªncia ultra-baixa**: RabbitMQ Ã© mais rÃ¡pido para operaÃ§Ãµes simples
- âŒ **Routing complexo**: RabbitMQ tem padrÃµes de roteamento mais avanÃ§ados
- âŒ **Simplicidade**: Setup Kafka Ã© mais complexo que alternativas
- âŒ **Poucos dados**: Overhead operacional pode nÃ£o compensar
- âŒ **Sem necessidade de reprocessamento**: Mensagens descartadas apÃ³s consumo

---

## ğŸ CaracterÃ­sticas Principais

| CaracterÃ­stica            | DescriÃ§Ã£o                                          |
| ------------------------- | -------------------------------------------------- |
| **Producer ConfigurÃ¡vel** | Batching, retries, timeouts, sync/async            |
| **Consumer Robusto**      | Heartbeat, rebalancing, commit automÃ¡tico          |
| **Message Translation**   | SerializaÃ§Ã£o JSON e header mapping automÃ¡tico      |
| **TLS Support**           | ConexÃ£o segura com brokers Kafka                   |
| **Distributed Tracing**   | OpenTelemetry integrado para observabilidade       |
| **Context Support**       | Cancelamento e timeouts via context Go             |
| **Topic Configuration**   | Suporte a groupos, partiÃ§Ãµes, mÃºltiplos tÃ³picos    |
| **Performance Tuning**    | BatchSize, BatchBytes, QueueCapacity configurÃ¡veis |
| **Consumer Group**        | Rebalancing automÃ¡tico entre consumers             |
| **Offset Management**     | Commit automÃ¡tico com intervalo configurÃ¡vel       |

---

## ğŸ”§ ImplementaÃ§Ã£o Detalhada

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     APLICAÃ‡ÃƒO GOMES                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         CommandBus / EventBus / Consumer              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            â”‚            â”‚
        â–¼            â–¼            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Connect â”‚  â”‚OutboundAdapterâ”‚  â”‚InboundAdapterâ”‚
    â”‚ ion    â”‚  â”‚  (Publisher) â”‚  â”‚  (Consumer) â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  MessageTranslator   â”‚
            â”‚  (Serialization)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Kafka Client (segmentio)   â”‚
            â”‚  - Producer/Writer          â”‚
            â”‚  - Consumer/Reader          â”‚
            â”‚  - Dialer/Transport         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Apache Kafka Cluster         â”‚
            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
            â”‚  â”‚ Broker1  â”‚ Broker2     â”‚   â”‚
            â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
            â”‚  â”‚ â”‚ Topic1 (Parte 1) â”‚   â”‚   â”‚
            â”‚  â”‚ â”‚ Topic1 (Parte 2) â”‚   â”‚   â”‚
            â”‚  â”‚ â”‚ Topic1 (Parte 3) â”‚   â”‚   â”‚
            â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Dados - PublicaÃ§Ã£o

```
AplicaÃ§Ã£o Command/Event
    â†“
MessageBuilder construi mensagem
    â†“
EventBus/CommandBus envia
    â†“
OutboundChannelAdapter recebe
    â†“
MessageTranslator serializa (JSON)
    â†“
Extrai headers e adiciona trace context
    â†“
Kafka Producer agrega (batch)
    â†“
Kafka Producer envia para broker
    â†“
Broker confirma (ack)
    â†“
Producer retorna sucesso
    â†“
AplicaÃ§Ã£o continua
```

### Fluxo de Dados - Consumo

```
Kafka Broker tem mensagens no tÃ³pico
    â†“
Kafka Consumer lÃª em batches
    â†“
InboundChannelAdapter recebe
    â†“
MessageTranslator desserializa (JSON)
    â†“
ReconstrÃ³i headers e trace context
    â†“
EventDrivenConsumer processa via handlers
    â†“
Handler executa lÃ³gica de negÃ³cio
    â†“
Se OK: Consumer faz commit do offset
    â†“
Se ERRO: Vai para Dead Letter Queue (opcional)
    â†“
Consumer aguarda prÃ³xima mensagem
```

### Componentes Internos

**Connection**:

- Gerencia Dialer (conexÃ£o TCP para cluster)
- Gerencia Transport (multiplexing de requisiÃ§Ãµes)
- Suporte a TLS para seguranÃ§a
- ReusÃ¡vel entre producer e consumer

**OutboundChannelAdapter (Publisher)**:

- Usa Kafka Writer (producer)
- Agrupa mensagens em batches
- Suporta retries com backoff
- Pode ser sync ou async
- Rastreia via OpenTelemetry

**InboundChannelAdapter (Consumer)**:

- Usa Kafka Reader (consumer)
- MantÃ©m consumer group para rebalancing
- Commit automÃ¡tico de offsets
- Heartbeat para manter membership
- Suporta mÃºltiplos tÃ³picos

**MessageTranslator**:

- Serializa/desserializa JSON
- Mapeia headers interno â†” Kafka
- Propaga trace context automÃ¡tico
- Extrai CorrelationId como key

### CaracterÃ­sticas TÃ©cnicas

- **Thread-Safe**: âœ… Sim - Kafka Writer e Reader sÃ£o thread-safe
- **AssÃ­ncrono**: âœ… Sim - Producer/Consumer rodam em background
- **Idempotente**: âš ï¸ Parcial - Depends na configuraÃ§Ã£o de acks e retry
- **ConfigurÃ¡vel**: âœ… Sim - Builders pattern para todas as opÃ§Ãµes

---

## ğŸ“š MÃ©todos PÃºblicos

### Connection Management

#### NewConnection(name string, host []string, opts ...ConnectionOptions) \*connection

**Local**: [connection.go](kafka/connection.go#L55-L70)

**DescriÃ§Ã£o**: Cria nova conexÃ£o com cluster Kafka. A conexÃ£o Ã© singleton e reutilizada por producer/consumer.

**ParÃ¢metros**:

- `name`: Identificador da conexÃ£o (ex: "kafka")
- `host`: Lista de endereÃ§os de brokers (ex: []string{"localhost:9092"})
- `opts`: OpÃ§Ãµes de configuraÃ§Ã£o (ex: WithTlsConfig)

**Retorno**:

- `*connection`: ConexÃ£o configurada

**Exemplo**:

```go
// ConexÃ£o bÃ¡sica
conn := kafka.NewConnection("kafka", []string{"localhost:9092"})

// Com TLS
tlsConfig := &tls.Config{...}
conn := kafka.NewConnection(
    "kafka",
    []string{"kafka.prod:9093"},
    kafka.WithTlsConfig(tlsConfig),
)
```

#### Connect() error

**Local**: [connection.go](kafka/connection.go#L76-L92)

**DescriÃ§Ã£o**: Estabelece conexÃ£o com brokers Kafka. Cria Dialer e Transport para uso posterior.

**Retorno**:

- `error`: Erro se conexÃ£o falhar (broker offline, rede indisponÃ­vel, etc)

**Exemplo**:

```go
gomes.AddChannelConnection(kafka.NewConnection(...))
// Dentro do gomes.Start(), Connect() Ã© chamado automaticamente
```

---

### Publisher (Outbound Channel Adapter)

#### NewPublisherChannelAdapterBuilder(connectionReferenceName, topicName string)

**Local**: [outbound_channel_adapter.go](kafka/outbound_channel_adapter.go#L58-L73)

**DescriÃ§Ã£o**: Cria builder para configurar publisher Kafka. PadrÃ£o builder para setup fluenta.

**ParÃ¢metros**:

- `connectionReferenceName`: Nome da conexÃ£o (deve estar registrada)
- `topicName`: TÃ³pico Kafka para publicar

**Retorno**:

- `*publisherChannelAdapterBuilder`: Builder configurado

**Exemplo**:

```go
gomes.AddPublisherChannel(
    kafka.NewPublisherChannelAdapterBuilder("kafka", "order.events"),
)
```

#### WithMaxAttempts(attempts int) \*publisherChannelAdapterBuilder

**DescriÃ§Ã£o**: Define nÃºmero mÃ¡ximo de tentativas para enviar mensagem. Falhas causam retry.

**PadrÃ£o**: 10 tentativas

**Exemplo**:

```go
kafka.NewPublisherChannelAdapterBuilder("kafka", "events").
    WithMaxAttempts(5)  // Se falhar 5x, desiste
```

#### WithBatchSize(size int) \*publisherChannelAdapterBuilder

**DescriÃ§Ã£o**: Agrupa mensagens antes de enviar. Maior batch = melhor throughput, maior latÃªncia.

**PadrÃ£o**: 100 mensagens por batch

**Exemplo**:

```go
// Para alto volume
builder.WithBatchSize(1000)  // Agrupa 1000 mensagens

// Para baixa latÃªncia
builder.WithBatchSize(10)    // Envia batches pequenos rÃ¡pido
```

#### WithBatchBytes(bytes int64) \*publisherChannelAdapterBuilder

**DescriÃ§Ã£o**: Limita tamanho mÃ¡ximo do batch em bytes. Producer envia quando atinge batch size OU batch bytes.

**PadrÃ£o**: 1048576 bytes (1 MB)

**Exemplo**:

```go
builder.WithBatchBytes(5242880)  // 5 MB por batch
```

#### WithAsync(async bool) \*publisherChannelAdapterBuilder

**DescriÃ§Ã£o**: Modo de envio. Async retorna imediatamente, sync aguarda confirmaÃ§Ã£o.

**PadrÃ£o**: true (assincronous)

**Exemplo**:

```go
// Fire and forget (rÃ¡pido, sem confirmaÃ§Ã£o)
builder.WithAsync(true)

// Aguardar confirmaÃ§Ã£o (seguro, mais lento)
builder.WithAsync(false)
```

#### WithRequiredAcks(acks int) \*publisherChannelAdapterBuilder

**DescriÃ§Ã£o**: NÃ­vel de confirmaÃ§Ã£o Kafka. 0=nenhum, 1=leader, -1=all replicas.

**PadrÃ£o**: 0 (nenhuma confirmaÃ§Ã£o)

**Exemplo**:

```go
// CrÃ­tico - confirmaÃ§Ã£o de todas as replicas
builder.WithRequiredAcks(-1)

// RÃ¡pido - sem confirmaÃ§Ã£o
builder.WithRequiredAcks(0)
```

---

### Consumer (Inbound Channel Adapter)

#### NewConsumerChannelAdapterBuilder(connectionReferenceName, topicName, consumerName string)

**Local**: [inbound_channel_adapter.go](kafka/inbound_channel_adapter.go#L59-L76)

**DescriÃ§Ã£o**: Cria builder para configurar consumer Kafka. Consumer group para rebalancing automÃ¡tico.

**ParÃ¢metros**:

- `connectionReferenceName`: Nome da conexÃ£o registrada
- `topicName`: TÃ³pico Kafka para consumir
- `consumerName`: Nome do grupo (deve ser Ãºnico entre serviÃ§os)

**Retorno**:

- `*consumerChannelAdapterBuilder`: Builder configurado

**Exemplo**:

```go
gomes.AddConsumerChannel(
    kafka.NewConsumerChannelAdapterBuilder(
        "kafka",
        "order.events",
        "order-service-consumer-group",
    ),
)
```

#### WithPartition(partition int) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: Consome apenas de uma partiÃ§Ã£o especÃ­fica. Ãštil para processamento ordenado.

**Exemplo**:

```go
// Apenas partiÃ§Ã£o 0 (garante ordem)
builder.WithPartition(0)

// Sem especificar: consome de todas as partiÃ§Ãµes
```

#### WithQueueCapacity(capacity int) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: Tamanho do buffer para fetch requests. Maior = menos roundtrips ao broker.

**PadrÃ£o**: 1000

**Exemplo**:

```go
builder.WithQueueCapacity(5000)  // Buffer maior para throughput
```

#### WithMinBytes(minBytes int) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: MÃ­nimo de bytes que broker aguarda antes de enviar. Maior = menos requisiÃ§Ãµes.

**PadrÃ£o**: 1 byte

**Exemplo**:

```go
builder.WithMinBytes(1024)  // Espera pelo menos 1KB de dados
```

#### WithMaxBytes(maxBytes int) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: MÃ¡ximo de bytes para fetch. Prevent muito dados em uma requisiÃ§Ã£o.

**PadrÃ£o**: 1048576 (1 MB)

**Exemplo**:

```go
builder.WithMaxBytes(5242880)  // MÃ¡ximo 5MB por fetch
```

#### WithMaxWait(duration time.Duration) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: Tempo mÃ¡ximo que broker aguarda dados antes de enviar resposta vazia.

**PadrÃ£o**: 100ms

**Exemplo**:

```go
builder.WithMaxWait(500 * time.Millisecond)
```

#### WithReadBatchTimeout(timeout time.Duration) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: Timeout para ler um batch de mensagens.

**PadrÃ£o**: 10s

**Exemplo**:

```go
builder.WithReadBatchTimeout(30 * time.Second)
```

#### WithHeartbeatInterval(interval time.Duration) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: FrequÃªncia de heartbeat para manter membership no group. Heartbeat muito raro pode causar timeout.

**PadrÃ£o**: 3s

**Exemplo**:

```go
builder.WithHeartbeatInterval(5 * time.Second)
```

#### WithCommitInterval(interval time.Duration) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: Intervalo para commit automÃ¡tico de offsets. Commit frequente = seguranÃ§a, commit raro = performance.

**PadrÃ£o**: 5s

**Exemplo**:

```go
// Commits rÃ¡pido (mais seguro contra falhas)
builder.WithCommitInterval(1 * time.Second)

// Commits lento (melhor performance)
builder.WithCommitInterval(30 * time.Second)
```

#### WithPartitionWatchInterval(interval time.Duration) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: FrequÃªncia para detectar mudanÃ§as de partiÃ§Ã£o (add/remove).

**PadrÃ£o**: 5m (5 minutos)

**Exemplo**:

```go
builder.WithPartitionWatchInterval(10 * time.Second)
```

#### WithWatchPartitionChanges(watch bool) \*consumerChannelAdapterBuilder

**DescriÃ§Ã£o**: Habilitar/desabilitar vigilÃ¢ncia de mudanÃ§as de partiÃ§Ã£o.

**PadrÃ£o**: false

**Exemplo**:

```go
// Rebalancear se tÃ³pico escalar
builder.WithWatchPartitionChanges(true)
```

---

## ğŸ—ï¸ Diagrama de Componentes

```mermaid
graph TB
    App["ğŸš€ AplicaÃ§Ã£o Gomes<br/>(CommandBus/EventBus)"]

    ConnBuilder["ğŸ”Œ NewConnection()"]
    PubBuilder["ğŸ“¤ NewPublisherChannelAdapterBuilder()"]
    ConBuilder["ğŸ“¥ NewConsumerChannelAdapterBuilder()"]

    Gomes["âœ… gomes.Start()<br/>(Inicializa tudo)"]

    Conn["ğŸ”— Connection<br/>(Dialer + Transport)"]

    Pub["ğŸ“¤ OutboundChannelAdapter<br/>(Kafka Writer)"]
    Con["ğŸ“¥ InboundChannelAdapter<br/>(Kafka Reader)"]

    Trans["ğŸ”„ MessageTranslator<br/>(JSON + Headers)"]

    KafkaWriter["âœï¸ Kafka Writer<br/>(Batching/Retry)"]
    KafkaReader["ğŸ“– Kafka Reader<br/>(Consume/Commit)"]

    Kafka["ğŸ­ Apache Kafka Cluster<br/>(Brokers + Partitions)"]

    App -->|Configure| ConnBuilder
    App -->|Configure| PubBuilder
    App -->|Configure| ConBuilder
    App -->|Inicializar| Gomes

    ConnBuilder -->|Create| Conn
    PubBuilder -->|Build| Pub
    ConBuilder -->|Build| Con

    Gomes -->|Connect| Conn
    Gomes -->|Create| Pub
    Gomes -->|Create| Con

    Pub -->|Translate| Trans
    Con -->|Translate| Trans

    Trans -->|Use| KafkaWriter
    Trans -->|Use| KafkaReader

    KafkaWriter -->|âœï¸ Write| Kafka
    KafkaReader -->|ğŸ“– Read| Kafka

    style App fill:#e1f5e1,stroke:#4caf50
    style Conn fill:#e3f2fd,stroke:#2196f3
    style Pub fill:#fff3cd,stroke:#ff9800
    style Con fill:#fff3cd,stroke:#ff9800
    style Trans fill:#f3e5f5,stroke:#9c27b0
    style Kafka fill:#ffebee,stroke:#f44336
    style Gomes fill:#e0f2f1,stroke:#009688
```

---

## ğŸ”„ Diagrama de ExecuÃ§Ã£o

```mermaid
sequenceDiagram
    participant App as AplicaÃ§Ã£o
    participant Gomes as Gomes Framework
    participant Conn as Connection
    participant Pub as Publisher
    participant Trans as Translator
    participant Kafka as Kafka Cluster

    App->>Gomes: AddChannelConnection(Kafka)
    App->>Gomes: AddPublisherChannel(Topic)
    App->>Gomes: Start()

    activate Gomes
    Gomes->>Conn: Connect()
    activate Conn
    Conn->>Kafka: TCPDial
    Kafka-->>Conn: Connected
    Conn-->>Gomes: OK
    deactivate Conn

    Gomes->>Pub: Build()
    Pub->>Kafka: CreateWriter
    Kafka-->>Pub: Writer Ready
    Gomes-->>App: System Ready
    deactivate Gomes

    App->>App: event := EventCreated{}
    App->>Gomes: EventBus.Publish(event)

    activate Gomes
    Gomes->>Pub: Send(message)
    activate Pub

    Pub->>Trans: Serialize(message)
    activate Trans
    Trans->>Trans: JSON Marshal
    Trans->>Trans: Extract Headers
    Trans-->>Pub: KafkaMessage
    deactivate Trans

    Pub->>Pub: Batch Message
    Pub->>Kafka: WriteMessages(batch)
    activate Kafka
    Kafka->>Kafka: Persist
    Kafka-->>Pub: Confirmed
    deactivate Kafka

    Pub-->>Gomes: Success
    deactivate Pub

    Gomes-->>App: Published
    deactivate Gomes
```

---

## ğŸ’¡ Exemplo de Uso PrÃ¡tico

### Setup Completo com Kafka

```go
package main

import (
    "context"
    "log/slog"
    "os"

    "github.com/jeffersonbrasilino/gomes"
    kafka "github.com/jeffersonbrasilino/gomes/channel/kafka"
)

// Definir evento
type OrderCreatedEvent struct {
    OrderID string `json:"orderId"`
    Amount  float64 `json:"amount"`
}

func (e *OrderCreatedEvent) Name() string {
    return "orderCreated"
}

// Definir handler
type OrderCreatedHandler struct{}

func (h *OrderCreatedHandler) Handle(
    ctx context.Context,
    event *OrderCreatedEvent,
) (any, error) {
    slog.Info("Processando evento",
        "orderId", event.OrderID,
        "amount", event.Amount,
    )
    return nil, nil
}

func main() {
    // 1. Configurar Kafka Connection
    slog.Info("Registrando Kafka...")
    gomes.AddChannelConnection(
        kafka.NewConnection("kafka", []string{"localhost:9092"}),
    )

    // 2. Configurar Publisher
    slog.Info("Registrando Publisher...")
    gomes.AddPublisherChannel(
        kafka.NewPublisherChannelAdapterBuilder("kafka", "order.events").
            WithBatchSize(100).
            WithMaxAttempts(5).
            WithAsync(true),
    )

    // 3. Configurar Consumer
    slog.Info("Registrando Consumer...")
    gomes.AddConsumerChannel(
        kafka.NewConsumerChannelAdapterBuilder(
            "kafka",
            "order.events",
            "order-service-group",
        ).
            WithHeartbeatInterval(5 * time.Second).
            WithCommitInterval(10 * time.Second),
    )

    // 4. Registrar Handler
    slog.Info("Registrando Handler...")
    gomes.AddActionHandler(&OrderCreatedHandler{})

    // 5. Inicializar
    slog.Info("Iniciando Gomes...")
    if err := gomes.Start(); err != nil {
        slog.Error("Erro ao iniciar", "err", err)
        os.Exit(1)
    }
    defer gomes.Shutdown()

    // 6. Publicar Evento
    slog.Info("Publicando evento...")
    eventBus, _ := gomes.EventBusByChannel("order.events")
    err := eventBus.Publish(context.Background(), &OrderCreatedEvent{
        OrderID: "ORD-12345",
        Amount:  299.99,
    })
    if err != nil {
        slog.Error("Erro publicar", "err", err)
    }

    // 7. Consumir Eventos
    slog.Info("Iniciando consumer...")
    consumer, _ := gomes.EventDrivenConsumer("order-service-group")
    err = consumer.
        WithAmountOfProcessors(4).
        WithMessageProcessingTimeout(30000).
        Run(context.Background())

    if err != nil {
        slog.Error("Consumer error", "err", err)
    }
}
```

### ConfiguraÃ§Ã£o Otimizada para Alto Volume

```go
// Publisher otimizado para throughput
gomes.AddPublisherChannel(
    kafka.NewPublisherChannelAdapterBuilder("kafka", "events").
        WithBatchSize(1000).         // Agrupa 1000 mensagens
        WithBatchBytes(5242880).     // 5MB mÃ¡ximo
        WithMaxAttempts(3).          // Menos retries
        WithAsync(true).             // Fire and forget
        WithRequiredAcks(1),         // Apenas leader confirma
)

// Consumer otimizado para throughput
gomes.AddConsumerChannel(
    kafka.NewConsumerChannelAdapterBuilder(
        "kafka", "events", "high-volume-consumer",
    ).
        WithQueueCapacity(5000).
        WithMinBytes(10240).
        WithMaxBytes(10485760).
        WithCommitInterval(1 * time.Second),
)
```

### ConfiguraÃ§Ã£o para Ordem Garantida

```go
// Uma partiÃ§Ã£o = ordem garantida
consumer, _ := gomes.EventDrivenConsumer("order-service")
consumer.
    WithPartition(0).                    // Apenas partiÃ§Ã£o 0
    WithAmountOfProcessors(1).           // 1 processor (sequencial)
    WithMessageProcessingTimeout(60000).
    Run(ctx)
```

---

## âœ… Boas PrÃ¡ticas

- âœ… **Use batch size apropriado**: 100-1000 para produÃ§Ã£o, teste para seu caso
- âœ… **Habilite commits frequentes**: 1-5s para evitar reprocessamento em falhas
- âœ… **Configure heartbeat < max.poll.interval**: Heartbeat 3s, max poll 5-10s
- âœ… **Use consumer groups**: Permite rebalancing e escalabilidade
- âœ… **Monitore lag de consumer**: Quantas mensagens ficaram para trÃ¡s
- âœ… **Implemente idempotÃªncia**: Suporte a reprocessamento sem side effects
- âœ… **Use acks=-1 para crÃ­tico**: Trade performance por seguranÃ§a em dados crÃ­ticos
- âœ… **Escale consumer horizontalmente**: Mais consumers = mais partiÃ§Ãµes processadas
- âœ… **Observe via OpenTelemetry**: Habilite traces para visibilidade end-to-end
- âœ… **Teste rebalancing**: Simule falha de brokers e recuperaÃ§Ã£o

### Erros Comuns a Evitar

- âŒ **Sem connection registrada**: Registre tambÃ©m com `gomes.AddChannelConnection()`
- âŒ **Consumer group name similar**: Names diferentes = diferentes grupos, sem rebalancing
- âŒ **Heartbeat > max poll**: Consumer sai do grupo se nÃ£o ler mensagens rÃ¡pido
- âŒ **Commit muito rÃ¡pido**: Muita carga no cluster, nem sempre necessÃ¡rio
- âŒ **Commit muito lento**: Se cair, reprocessa muitas mensagens
- âŒ **Partition sem processadores suficientes**: Bottleneck, lag cresce
- âŒ **Sem tratamento de erro**: Mensagens falham silenciosamente
- âŒ **TLS com ca invÃ¡lido**: ConexÃ£o falha com erro criptografado confuso

---

## ğŸ” Troubleshooting

### Problema: "Connection refused" ao iniciar

**Sintomas**:

- `dial tcp: connection refused` no startup
- Consumer/Publisher nÃ£o inicia

**Causa**: Kafka broker nÃ£o estÃ¡ rodando ou endereÃ§o incorreto

**SoluÃ§Ã£o**:

```bash
# Verificar se Kafka estÃ¡ rodando
docker ps | grep kafka

# Testar conectividade
telnet localhost 9092

# Corrigir endereÃ§o se necessÃ¡rio
gomes.AddChannelConnection(
    kafka.NewConnection("kafka", []string{"kafka:9092"}),  // host correto
)
```

---

### Problema: Consumer nÃ£o processa mensagens

**Sintomas**:

- Consumer iniciado
- Mensagens publicadas com sucesso
- Nada Ã© processado
- Sem erros nos logs

**Causa**:

1. Handler nÃ£o registrado
2. TÃ³pico invÃ¡lido
3. Consumer group mal configurado

**SoluÃ§Ã£o**:

```go
// 1. Verificar handler registrado
gomes.AddActionHandler(&OrderCreatedHandler{})  // ANTES de Start()

// 2. Verificar nome do eventos
type OrderCreatedEvent struct {}
func (e *OrderCreatedEvent) Name() string {
    return "orderCreated"  // Deve bater com handler
}

// 3. Mostrar endpoints ativos
gomes.ShowActiveEndpoints()
// Deve aparecer consumer "order-service-group"
```

---

### Problema: Consumer lag cresce indefinidamente

**Sintomas**:

- Mensagens ficam no tÃ³pico sem ser processadas
- Offset nÃ£o avanÃ§a
- Fila crescendo

**Causa**:

1. Processadores insuficientes
2. Handler muito lento
3. Erro no handler (retry loop)

**SoluÃ§Ã£o**:

```go
// Aumentar processadores para paralelismo
consumer.WithAmountOfProcessors(8)  // Mais workers

// Aumentar timeout se operaÃ§Ã£o Ã© lenta
consumer.WithMessageProcessingTimeout(60000)  // 60s

// Verificar logs do handler
// Se houver erro, mensagem pode ficar em retry
```

---

### Problema: Mensagens duplicadas sÃ£o processadas

**Sintomas**:

- Mesmo evento processado mÃºltiplas vezes
- DuplicaÃ§Ã£o aleatÃ³ria

**Causa**: Consumer caiu depois de processar mas antes de commit

**SoluÃ§Ã£o**: Implementar idempotÃªncia

```go
func (h *OrderCreatedHandler) Handle(
    ctx context.Context,
    event *OrderCreatedEvent,
) (any, error) {
    // 1. Usar deduplication ID
    dedupeID := fmt.Sprintf("order:%s:created", event.OrderID)

    // 2. Verificar se jÃ¡ processou
    exists := db.Exists(ctx, dedupeID)
    if exists {
        return nil, nil  // JÃ¡ processado, skip
    }

    // 3. Processar
    order := CreateOrder(event)

    // 4. Marcar como processado ATOMICAMENTE
    db.SetAtomic(ctx, dedupeID, true)

    return nil, nil
}
```

---

### Problema: "not a member for group" error

**Sintomas**:

- Consumer falha com erro de group membership
- Frequente rebalancing

**Causa**: Heartbeat ou max poll interval incorreto

**SoluÃ§Ã£o**:

```go
// Ajustar tempos
builder.
    WithHeartbeatInterval(3 * time.Second).    // Heartbeat rÃ¡pido
    WithReadBatchTimeout(30 * time.Second).    // Max poll 30s

// Heartbeat deve ser < max poll
// Regra: heartbeat = max poll / 3
```

---

### Problema: Kafka producers estÃ£o lentos

**Sintomas**:

- Publish toma muito tempo
- Throughput pequeno

**Causa**: Batch size pequeno, required acks alto

**SoluÃ§Ã£o**:

```go
// Aumentar batch para agrupar mais
builder.WithBatchSize(500)

// Usar acks=1 em vez de -1
builder.WithRequiredAcks(1)

// Usar async (padrÃ£o)
builder.WithAsync(true)
```

---

## ğŸ“š ReferÃªncias

### DocumentaÃ§Ã£o Interna

- [Gomes Bootstrap](gomes-bootstrap.md): Como inicializar Gomes
- [Event Processing Flow](event-processing-flow.md): Como publicar eventos
- [Event-Driven Consumer](event-driven-consumer.md): Como consumir eventos

### DocumentaÃ§Ã£o Externa

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/): DocumentaÃ§Ã£o oficial
- [Kafka Go Client (segmentio)](https://github.com/segmentio/kafka-go): Cliente usado pelo Gomes
- [Kafka Producer Tuning](https://kafka.apache.org/documentation/#producerconfigs): Producer config
- [Kafka Consumer Tuning](https://kafka.apache.org/documentation/#consumerconfigs): Consumer config
- [Kafka Rebalancing](https://kafka.apache.org/documentation/#intro_consumers): Consumer group protocol
- [Event Sourcing with Kafka](https://martinfowler.com/articles/event-sourcing.html): PadrÃ£o Event Sourcing

---

## ğŸ“ PrÃ³ximos Passos

1. **Iniciante**: Use setup bÃ¡sico com defaults
2. **IntermediÃ¡rio**: Ajuste batch sizes e timeouts para seu workload
3. **AvanÃ§ado**: Implemente reprocessamento, Event Sourcing, rebalancing customizado

---

**Ãšltima AtualizaÃ§Ã£o**: 16 de fevereiro de 2026  
**Status**: âœ… ProduÃ§Ã£o  
**VersÃ£o do Gomes**: v1.0+  
**VersÃ£o Kafka**: Suporta 0.11+
